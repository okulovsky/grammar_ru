{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from tg.grammar_ru import CorpusReader\n",
    "from tg.projects.book_fragments.fragments_builder import FragmentsBuilder\n",
    "from tg.projects.book_fragments.ru_localizator import RussianLocalizator\n",
    "from tg.projects.book_fragments.eng_localizator import EnglishLocalizator\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip_eng_corpus = Path('./files/corpuses/eng_crime_and_puhishment.base.zip')\n",
    "cip_ru_corpus = Path('./files/corpuses/ru_crime_and_puhishment.base.zip')\n",
    "fragments_builder = FragmentsBuilder(cip_eng_corpus, output_path=\"./files/fragments\", file_name=\"eng_cip_fragments\")\n",
    "fragments_builder.construct_fragments_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./files/fragments/eng_cip_fragments.json\")\n",
    "data = json.load(file)\n",
    "file.close()\n",
    "\n",
    "for fragment in data[\"fragments\"]:\n",
    "    input(\"next fragment\")\n",
    "    print(fragment['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "martin_reader = CorpusReader(Path('../retell/featurized_corpuses/books/eng/Martin.featurized.books.corpus.zip'))\n",
    "\n",
    "frame = martin_reader.get_frames().first()\n",
    "# frame[frame[\"sentence_id\"] == 9]\n",
    "\n",
    "count_extra_sentences = 0\n",
    "extra_sentences_id = []\n",
    "for sentence_id in frame[\"sentence_id\"].unique():\n",
    "    stop_counter = 0\n",
    "    for word in frame[frame[\"sentence_id\"] == sentence_id][\"word\"]:\n",
    "        if word == '.':\n",
    "            stop_counter += 1\n",
    "    if stop_counter > 1:\n",
    "        extra_sentences_id.append((sentence_id, stop_counter - 1))\n",
    "        count_extra_sentences += 1\n",
    "\n",
    "print(count_extra_sentences)\n",
    "print(extra_sentences_id)\n",
    "\n",
    "print(frame[frame[\"sentence_id\"] == 371])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating fragments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame with id: 23d70373-882f-49e5-bb3a-1d87659de82b, 7/7\r"
     ]
    }
   ],
   "source": [
    "corpus = Path('./files/corpuses/eng_crime_and_puhishment.base.zip')\n",
    "fragments_builder = FragmentsBuilder(corpus, file_name=\"eng_cip_fragments\", localizator=EnglishLocalizator())\n",
    "fragments_builder.construct_fragments_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('./fragments/ru_books_fragments.json')) as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "    for fragment in json_data['fragments']:\n",
    "        print(fragment['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116225\n"
     ]
    }
   ],
   "source": [
    "corpus = Path('./files/corpuses/eng_crime_and_puhishment.base.zip')\n",
    "corpus_reader = CorpusReader(corpus)\n",
    "\n",
    "frame = corpus_reader.get_frames().skip(2).first()\n",
    "\n",
    "print(frame[\"paragraph_id\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open-chat-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:5000/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "history = []\n",
    "json_file = open(Path('./fragments/martin_fragments.json'))\n",
    "json_data = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "for fragment in json_data['fragments']:\n",
    "    print(fragment['text'])\n",
    "    user_message = fragment['text']\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    data = {\n",
    "        \"model\": \"openchat_3.5.Q5_K_M.gguf\",\n",
    "        \"messages\": history\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data, verify=False)\n",
    "    assistant_message = response.json()['choices'][0]['message']['content']\n",
    "    history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    print(assistant_message)\n",
    "    fragment['retell'] = assistant_message\n",
    "\n",
    "with open(Path('./fragments/martin_fragments.json'), 'w') as json_file:\n",
    "    json.dump(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
