{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff31bab",
   "metadata": {},
   "source": [
    "# Data Formats\n",
    "\n",
    "In this research we use tabular representation of words in the text. This is not how text is represented in e.g. Hugging Face Transformers Models, where words are usually decomposed into the sequence of tokens. Tokens approach simply would provide us much more information than needed to solve the tasks we want, and we would need to deal with large datasets to avoid overfitting. Instead, we want to provide less precise information about each word, such as Pymorphy or Slovnet outputs. Hence, organizing this data in text is needed.\n",
    "\n",
    "In this demo we show the set of classes that encapsulate the tedious preprocessing of text, such as separation into sentences/words and running well-known solutions on it. This is done under the hood, so after running a few routines we can get data in tabular format and dive directly into interesting tasks instead of peculiarities of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2558b",
   "metadata": {},
   "source": [
    "## Separator\n",
    "\n",
    "Separator is the class that process the text and produces a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daefa0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Маги</td>\n",
       "      <td>ru</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>только</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>думали</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>что</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  word_index  paragraph_id  word_tail    word  \\\n",
       "0        0            0           0             0          1    Маги   \n",
       "1        1            0           1             0          1  только   \n",
       "2        2            0           2             0          0  думали   \n",
       "3        3            0           3             0          1       ,   \n",
       "4        4            0           4             0          1     что   \n",
       "\n",
       "  word_type  word_length  \n",
       "0        ru            4  \n",
       "1        ru            6  \n",
       "2        ru            6  \n",
       "3     punct            1  \n",
       "4        ru            3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grammar_ru import Separator\n",
    "\n",
    "text = 'Маги только думали, что могут контролировать информационную среду, но на самом деле все происходило по таким же биологическим законам, по которым рыбы в океане выбирают, куда им плыть. Это не люди выстраивали картину мира, а картина мира выстраивала себя через них. Бесполезно было искать виноватых.'\n",
    "df = Separator.separate_string(text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf2eb7",
   "metadata": {},
   "source": [
    "Columns' names are mostly self-explaining.\n",
    "* `word_tail` is the amount of spaces that followed the word in the original text. `\n",
    "* `word_id`, `sentence_id`, `paragraph_id` must be unique in the whole corpus.\n",
    "* `word_index` is the position of the word inside the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a9d1a",
   "metadata": {},
   "source": [
    "Once separated, text can be viewed with `Separator.Viewer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde01c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Бесполезно было искать виноватых.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Separator.Viewer().to_text(df.loc[df.sentence_id==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a88e39",
   "metadata": {},
   "source": [
    "## Bundle\n",
    "\n",
    "Bundle is a set of named dataframes, typically describing the same text.\n",
    "\n",
    "Separator can run featurizers on the text, placing the output of each featurizer into one or several dataframes in the bundle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d8d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammar_ru.features import PyMorphyFeaturizer, SlovnetFeaturizer\n",
    "\n",
    "db = Separator.build_bundle(text, [PyMorphyFeaturizer(), SlovnetFeaturizer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4334a774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src', 'pymorphy', 'slovnet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27a2ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Маги</td>\n",
       "      <td>ru</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>только</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>думали</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>что</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  word_index  paragraph_id  word_tail    word  \\\n",
       "0        0            0           0             0          1    Маги   \n",
       "1        1            0           1             0          1  только   \n",
       "2        2            0           2             0          0  думали   \n",
       "3        3            0           3             0          1       ,   \n",
       "4        4            0           4             0          1     что   \n",
       "\n",
       "  word_type  word_length  \n",
       "0        ru            4  \n",
       "1        ru            6  \n",
       "2        ru            6  \n",
       "3     punct            1  \n",
       "4        ru            3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.data_frames['src'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3984b7",
   "metadata": {},
   "source": [
    "Data bundle allows **read-only** accessing of the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca04b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Маги</td>\n",
       "      <td>ru</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>только</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>думали</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>что</td>\n",
       "      <td>ru</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  word_index  paragraph_id  word_tail    word  \\\n",
       "0        0            0           0             0          1    Маги   \n",
       "1        1            0           1             0          1  только   \n",
       "2        2            0           2             0          0  думали   \n",
       "3        3            0           3             0          1       ,   \n",
       "4        4            0           4             0          1     что   \n",
       "\n",
       "  word_type  word_length  \n",
       "0        ru            4  \n",
       "1        ru            6  \n",
       "2        ru            6  \n",
       "3     punct            1  \n",
       "4        ru            3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.src.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eed4d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_form</th>\n",
       "      <th>alternatives</th>\n",
       "      <th>score</th>\n",
       "      <th>delta_score</th>\n",
       "      <th>POS</th>\n",
       "      <th>animacy</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "      <th>case</th>\n",
       "      <th>aspect</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>person</th>\n",
       "      <th>tense</th>\n",
       "      <th>mood</th>\n",
       "      <th>voice</th>\n",
       "      <th>involvement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>маг</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>anim</td>\n",
       "      <td>masc</td>\n",
       "      <td>plur</td>\n",
       "      <td>nomn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>только</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>ADVB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>думать</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impf</td>\n",
       "      <td>intr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>past</td>\n",
       "      <td>indc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>что</td>\n",
       "      <td>5</td>\n",
       "      <td>0.922033</td>\n",
       "      <td>0.891525</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        normal_form  alternatives     score  delta_score   POS animacy gender  \\\n",
       "word_id                                                                         \n",
       "0               маг             1  1.000000     1.000000  NOUN    anim   masc   \n",
       "1            только             3  0.500000     0.250000  ADVB     NaN    NaN   \n",
       "2            думать             2  0.500000     0.000000  VERB     NaN    NaN   \n",
       "3                 ,             1  1.000000     1.000000  NONE     NaN    NaN   \n",
       "4               что             5  0.922033     0.891525  CONJ     NaN    NaN   \n",
       "\n",
       "        number  case aspect transitivity person tense  mood voice involvement  \n",
       "word_id                                                                        \n",
       "0         plur  nomn    NaN          NaN    NaN   NaN   NaN  None        None  \n",
       "1          NaN   NaN    NaN          NaN    NaN   NaN   NaN  None        None  \n",
       "2         plur   NaN   impf         intr    NaN  past  indc  None        None  \n",
       "3          NaN   NaN    NaN          NaN    NaN   NaN   NaN  None        None  \n",
       "4          NaN   NaN    NaN          NaN    NaN   NaN   NaN  None        None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.pymorphy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2672a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Animacy</th>\n",
       "      <th>Case</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Number</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Mood</th>\n",
       "      <th>Tense</th>\n",
       "      <th>VerbForm</th>\n",
       "      <th>Voice</th>\n",
       "      <th>Person</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>relation</th>\n",
       "      <th>syntax_parent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>Anim</td>\n",
       "      <td>Nom</td>\n",
       "      <td>Fem</td>\n",
       "      <td>Plur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advmod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plur</td>\n",
       "      <td>Imp</td>\n",
       "      <td>Ind</td>\n",
       "      <td>Past</td>\n",
       "      <td>Fin</td>\n",
       "      <td>Act</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punct</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           POS Animacy Case Gender Number Aspect Mood Tense VerbForm Voice  \\\n",
       "word_id                                                                      \n",
       "0         NOUN    Anim  Nom    Fem   Plur    NaN  NaN   NaN      NaN   NaN   \n",
       "1         PART     NaN  NaN    NaN    NaN    NaN  NaN   NaN      NaN   NaN   \n",
       "2         VERB     NaN  NaN    NaN   Plur    Imp  Ind  Past      Fin   Act   \n",
       "3        PUNCT     NaN  NaN    NaN    NaN    NaN  NaN   NaN      NaN   NaN   \n",
       "4        SCONJ     NaN  NaN    NaN    NaN    NaN  NaN   NaN      NaN   NaN   \n",
       "\n",
       "        Person Degree Polarity relation  syntax_parent_id  \n",
       "word_id                                                    \n",
       "0          NaN    NaN      NaN    nsubj                 2  \n",
       "1          NaN    NaN      NaN   advmod                 2  \n",
       "2          NaN    NaN      NaN     root                -1  \n",
       "3          NaN    NaN      NaN    punct                 5  \n",
       "4          NaN    NaN      NaN     mark                 5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.slovnet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5fb6a",
   "metadata": {},
   "source": [
    "Once text was featurized, basic statistical research may be performed with the `pandas` library. \n",
    "\n",
    "`Separator.Viewer` can additionaly be used to highlight the words in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfea8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><span style=\"background-color:#fb8072;\" title=\"PRCL\">Это</span> <span style=\"background-color:#fb8072;\" title=\"PRCL\">не</span> <span style=\"background-color:#8dd3c7;\" title=\"NOUN\">люди</span> <span style=\"background-color:#80b1d3;\" title=\"VERB\">выстраивали</span> <span style=\"background-color:#8dd3c7;\" title=\"NOUN\">картину</span> <span style=\"background-color:#8dd3c7;\" title=\"NOUN\">мира</span><span style=\"background-color:#ffffb3;\" title=\"NONE\">,</span> <span style=\"background-color:#fdb462;\" title=\"CONJ\">а</span> <span style=\"background-color:#8dd3c7;\" title=\"NOUN\">картина</span> <span style=\"background-color:#8dd3c7;\" title=\"NOUN\">мира</span> <span style=\"background-color:#80b1d3;\" title=\"VERB\">выстраивала</span> <span style=\"background-color:#bebada;\" title=\"NPRO\">себя</span> <span style=\"background-color:#b3de69;\" title=\"PREP\">через</span> <span style=\"background-color:#bebada;\" title=\"NPRO\">них</span><span style=\"background-color:#ffffb3;\" title=\"NONE\">.</span> </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = db.src.merge(db.pymorphy[['POS']], left_on='word_id', right_index=True)\n",
    "Separator.Viewer().highlight('POS','auto').tooltip('POS').to_html_display(df.loc[df.sentence_id==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ebe2e",
   "metadata": {},
   "source": [
    "## Corpus\n",
    "\n",
    "Corpus is a set of bundles, each representing one \"atomic\" text in the collection, e.g. a chapter in the book. \"Atomic\" means that the statistical operations we perform on this text can be performed within this one bundle, and we don't need to join across the bundles. Separation of texts into bundles is important to control the memory consumption: sometimes we need e.g. to merge dataframes with themselves, and such operations are too memory-intensive to be performed on the whole books. \n",
    "\n",
    "Corpuses are build from \"pseudo-md\" files that contain:\n",
    "\n",
    "* Headers, starting with `#`\n",
    "* Tags, starting with `$`\n",
    "* Raw text\n",
    "\n",
    "When building corpus from e.g. HTML files, those must first be converted into pseudomd format, and then fed to the `grammar_ru` pipelines. The advantage of this approach is that such pseudomd files can be reviewed manually.\n",
    "\n",
    "`grammar_ru` also contains the auxiliary code to convert `fb2` format into pseudomd.\n",
    "\n",
    "This is an example of md-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c9c897",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 48: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myo_fluq_ds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mFileIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiles/mds/averchenko.md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m200\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\site-packages\\yo_fluq_ds\\_misc\\io.py:32\u001b[0m, in \u001b[0;36mFileIO.read_text\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(filename):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 48: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from yo_fluq_ds import *\n",
    "\n",
    "print(FileIO.read_text('files/mds/averchenko.md')[:200]+'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a45731",
   "metadata": {},
   "source": [
    "This is how conversion works:\n",
    "\n",
    "* First, we convert the `md` files inside a specified folder into a base corpus\n",
    "* Second, we run the featurizers on the base corpus, producing the featurized corpus.\n",
    "\n",
    "Both corpuses are `zip`-files that are easy to spread around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee2dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d56968059a941959e94f6e2b47522e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 48: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m corpus \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles/corpus.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m base_corpus \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles/corpus.base.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mCorpusBuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_interformat_folder_to_corpus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_corpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiles/mds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m CorpusBuilder\u001b[38;5;241m.\u001b[39mfeaturize_corpus(\n\u001b[0;32m     15\u001b[0m     base_corpus,\n\u001b[0;32m     16\u001b[0m     corpus,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     ]\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\yura\\desktop\\repos\\grammar_ru\\grammar_ru\\corpus\\corpus_builder.py:74\u001b[0m, in \u001b[0;36mCorpusBuilder.convert_interformat_folder_to_corpus\u001b[1;34m(corpus_path, md_folder, naming, take_files_count)\u001b[0m\n\u001b[0;32m     71\u001b[0m     query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mtake(take_files_count)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(query\u001b[38;5;241m.\u001b[39mfeed(fluq\u001b[38;5;241m.\u001b[39mwith_progress_bar(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(files)))):\n\u001b[1;32m---> 74\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part_index, part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parsed):\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\yura\\desktop\\repos\\grammar_ru\\grammar_ru\\corpus\\corpus_builder.py:25\u001b[0m, in \u001b[0;36m_ParallelParser.__call__\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInterFormatParser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSRC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnaming\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\site-packages\\yo_fluq\\_push_queries\\aggregation_code_factory.py:70\u001b[0m, in \u001b[0;36mAggregationCodeFactory.to_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_list\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod_concatenator\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToList\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\site-packages\\yo_fluq_ds\\_queries\\queryable.py:12\u001b[0m, in \u001b[0;36mQueryable._aggregate_with\u001b[1;34m(self, aggregator)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aggregate_with\u001b[39m(\u001b[38;5;28mself\u001b[39m, aggregator: agg\u001b[38;5;241m.\u001b[39mPushQueryElement):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maggregator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43men\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\site-packages\\yo_fluq\\_push_queries\\arch.py:16\u001b[0m, in \u001b[0;36mAbstractPushQueryElement.__call__\u001b[1;34m(self, enumerable)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, enumerable: Iterable):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance() \u001b[38;5;28;01mas\u001b[39;00m agg:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m enumerable:\n\u001b[0;32m     17\u001b[0m             process_result \u001b[38;5;241m=\u001b[39m agg\u001b[38;5;241m.\u001b[39mprocess(element)\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(process_result,\u001b[38;5;167;01mStopIteration\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\users\\yura\\desktop\\repos\\grammar_ru\\grammar_ru\\corpus\\formats\\interformat_parser.py:158\u001b[0m, in \u001b[0;36mInterFormatParser._parse_iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m file_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prefix_tag()\n\u001b[0;32m    157\u001b[0m rel_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39mrelative_to(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder)\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (buffer, tags) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_base()):\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m file_tags\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    160\u001b[0m         tags[k]\u001b[38;5;241m=\u001b[39mv\n",
      "File \u001b[1;32mc:\\users\\yura\\desktop\\repos\\grammar_ru\\grammar_ru\\corpus\\formats\\interformat_parser.py:136\u001b[0m, in \u001b[0;36mInterFormatParser._parse_base\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmock\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mFileIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m parser \u001b[38;5;241m=\u001b[39m HeaderParser()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\site-packages\\yo_fluq_ds\\_misc\\io.py:32\u001b[0m, in \u001b[0;36mFileIO.read_text\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(filename):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gram\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 48: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from grammar_ru.corpus import CorpusBuilder\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = Path('files/corpus.zip')\n",
    "base_corpus = Path('files/corpus.base.zip')\n",
    "\n",
    "\n",
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    base_corpus,\n",
    "    Path('files/mds'),\n",
    "    ['author']\n",
    ")\n",
    "\n",
    "CorpusBuilder.featurize_corpus(\n",
    "    base_corpus,\n",
    "    corpus,\n",
    "    [\n",
    "        PyMorphyFeaturizer(),\n",
    "        SlovnetFeaturizer()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f2335",
   "metadata": {},
   "source": [
    "Corpus contains table-of-contents (toc) file, describing all bundles in the corpus: basic statistics, headers and tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dc0ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>part_index</th>\n",
       "      <th>token_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>header_0</th>\n",
       "      <th>headers</th>\n",
       "      <th>author</th>\n",
       "      <th>max_id</th>\n",
       "      <th>tag_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92c27d27-c4f7-43be-a40c-4004d880f228</th>\n",
       "      <td>chekhov.md</td>\n",
       "      <td>2023-02-12 14:00:46.016147</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>6010</td>\n",
       "      <td>0</td>\n",
       "      <td>Ванька</td>\n",
       "      <td>Ванька</td>\n",
       "      <td>chekhov</td>\n",
       "      <td>1423</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0f7eae2-130a-4abc-a0f7-5628da95ab59</th>\n",
       "      <td>averchenko.md</td>\n",
       "      <td>2023-02-12 14:00:46.174728</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "      <td>Баклуши</td>\n",
       "      <td>Баклуши</td>\n",
       "      <td>averchenko</td>\n",
       "      <td>11628</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d01bfc6c-6254-4c0b-b5de-15b67e944a76</th>\n",
       "      <td>averchenko.md</td>\n",
       "      <td>2023-02-12 14:00:46.197242</td>\n",
       "      <td>1</td>\n",
       "      <td>453</td>\n",
       "      <td>2035</td>\n",
       "      <td>2</td>\n",
       "      <td>Белые короли</td>\n",
       "      <td>Белые короли</td>\n",
       "      <td>averchenko</td>\n",
       "      <td>22082</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filename  \\\n",
       "file_id                                               \n",
       "92c27d27-c4f7-43be-a40c-4004d880f228     chekhov.md   \n",
       "f0f7eae2-130a-4abc-a0f7-5628da95ab59  averchenko.md   \n",
       "d01bfc6c-6254-4c0b-b5de-15b67e944a76  averchenko.md   \n",
       "\n",
       "                                                      timestamp  part_index  \\\n",
       "file_id                                                                       \n",
       "92c27d27-c4f7-43be-a40c-4004d880f228 2023-02-12 14:00:46.016147           0   \n",
       "f0f7eae2-130a-4abc-a0f7-5628da95ab59 2023-02-12 14:00:46.174728           0   \n",
       "d01bfc6c-6254-4c0b-b5de-15b67e944a76 2023-02-12 14:00:46.197242           1   \n",
       "\n",
       "                                      token_count  character_count  ordinal  \\\n",
       "file_id                                                                       \n",
       "92c27d27-c4f7-43be-a40c-4004d880f228         1422             6010        0   \n",
       "f0f7eae2-130a-4abc-a0f7-5628da95ab59          204              865        1   \n",
       "d01bfc6c-6254-4c0b-b5de-15b67e944a76          453             2035        2   \n",
       "\n",
       "                                          header_0       headers      author  \\\n",
       "file_id                                                                        \n",
       "92c27d27-c4f7-43be-a40c-4004d880f228        Ванька        Ванька     chekhov   \n",
       "f0f7eae2-130a-4abc-a0f7-5628da95ab59       Баклуши       Баклуши  averchenko   \n",
       "d01bfc6c-6254-4c0b-b5de-15b67e944a76  Белые короли  Белые короли  averchenko   \n",
       "\n",
       "                                      max_id  tag_rating  \n",
       "file_id                                                   \n",
       "92c27d27-c4f7-43be-a40c-4004d880f228    1423         NaN  \n",
       "f0f7eae2-130a-4abc-a0f7-5628da95ab59   11628        10.0  \n",
       "d01bfc6c-6254-4c0b-b5de-15b67e944a76   22082        20.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru import CorpusReader\n",
    "\n",
    "reader = CorpusReader(corpus)\n",
    "reader.get_toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d925b",
   "metadata": {},
   "source": [
    "`reader.read_frames()` provides an iterator with the `src` frames of each bundle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80cf95ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_index</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>word_tail</th>\n",
       "      <th>word</th>\n",
       "      <th>word_type</th>\n",
       "      <th>word_length</th>\n",
       "      <th>file_id</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ванька</td>\n",
       "      <td>ru</td>\n",
       "      <td>6</td>\n",
       "      <td>92c27d27-c4f7-43be-a40c-4004d880f228</td>\n",
       "      <td>corpus.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Жуков</td>\n",
       "      <td>ru</td>\n",
       "      <td>5</td>\n",
       "      <td>92c27d27-c4f7-43be-a40c-4004d880f228</td>\n",
       "      <td>corpus.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>1</td>\n",
       "      <td>92c27d27-c4f7-43be-a40c-4004d880f228</td>\n",
       "      <td>corpus.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>девятилетний</td>\n",
       "      <td>ru</td>\n",
       "      <td>12</td>\n",
       "      <td>92c27d27-c4f7-43be-a40c-4004d880f228</td>\n",
       "      <td>corpus.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>мальчик</td>\n",
       "      <td>ru</td>\n",
       "      <td>7</td>\n",
       "      <td>92c27d27-c4f7-43be-a40c-4004d880f228</td>\n",
       "      <td>corpus.zip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id  word_index  paragraph_id  word_tail          word  \\\n",
       "0        0            0           0             0          1        Ванька   \n",
       "1        1            0           1             0          0         Жуков   \n",
       "2        2            0           2             0          1             ,   \n",
       "3        3            0           3             0          1  девятилетний   \n",
       "4        4            0           4             0          0       мальчик   \n",
       "\n",
       "  word_type  word_length                               file_id   corpus_id  \n",
       "0        ru            6  92c27d27-c4f7-43be-a40c-4004d880f228  corpus.zip  \n",
       "1        ru            5  92c27d27-c4f7-43be-a40c-4004d880f228  corpus.zip  \n",
       "2     punct            1  92c27d27-c4f7-43be-a40c-4004d880f228  corpus.zip  \n",
       "3        ru           12  92c27d27-c4f7-43be-a40c-4004d880f228  corpus.zip  \n",
       "4        ru            7  92c27d27-c4f7-43be-a40c-4004d880f228  corpus.zip  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.read_frames().first().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795bdc6",
   "metadata": {},
   "source": [
    "`reader.read_bundles()` provides an iterator that reads the whole bundles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d79a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': {'shape': (1422, 10), 'index_name': None}, 'pymorphy': {'shape': (1422, 16), 'index_name': 'word_id'}, 'slovnet': {'shape': (1422, 16), 'index_name': 'word_id'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.read_bundles().first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
