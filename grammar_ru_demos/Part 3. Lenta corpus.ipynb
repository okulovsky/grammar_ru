{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce3987c",
   "metadata": {},
   "source": [
    "First, let's download Lenta corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2488615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corus\n",
    "from grammar_ru.common import Loc\n",
    "import subprocess\n",
    "import os\n",
    "PATH = Loc.temp_path/'lenta.gz'\n",
    "\n",
    "if not os.path.isfile(PATH):\n",
    "    subprocess.call([\n",
    "        'wget',\n",
    "        'https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz',\n",
    "        '-O',\n",
    "        PATH\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128d906",
   "metadata": {},
   "source": [
    "We will build a generator over `corus` reader for Lenta corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a3ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LentaRecord(\n",
       "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
       "    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n",
       "    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
       "    topic='Россия',\n",
       "    tags='Общество',\n",
       "    date=None\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yo_fluq_ds import Queryable\n",
    "\n",
    "def get_lenta():\n",
    "    return Queryable(corus.load_lenta(PATH), 739351)\n",
    "\n",
    "get_lenta().first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2bffd4",
   "metadata": {},
   "source": [
    "Then, we will stack all the texts from Lenta to larger files and store in md files. The reason for that is that Lenta items are very small, so if we won't stack them, it will create a corpus with lots of small dataframes. `grammar_ru` doesn't perform well in this case, it was designed more to deal with books, not small news entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4b8313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f53d3764d0a4defb474b36c9736aaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/739351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "from grammar_ru.common import FileIO\n",
    "\n",
    "PROCESSED = Loc.processed_path/'lenta'\n",
    "shutil.rmtree(PROCESSED, ignore_errors = True)\n",
    "os.makedirs(PROCESSED)\n",
    "\n",
    "buffer = []\n",
    "length = 0\n",
    "file_index = 0\n",
    "\n",
    "for rec in get_lenta().feed(fluq.with_progress_bar()):\n",
    "    buffer.append(rec.text)\n",
    "    length+=len(rec.text)\n",
    "    if length>1000000:\n",
    "        text = f'# Partition {file_index}\\n\\n'\n",
    "        text += '\\n\\n'.join(buffer)\n",
    "        FileIO.write_text(text, PROCESSED/f'{file_index}.md')\n",
    "        file_index+=1\n",
    "        buffer = []\n",
    "        length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb3a21",
   "metadata": {},
   "source": [
    "Now, we convert these `md` files to corpus. It takes a lot of time, but don't forget, this is a pretty large corpus, and tokenization and sentinization is applied to it along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec43466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c00b90f5efc4fc4ba7c5f38089c0c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grammar_ru.corpus import CorpusBuilder\n",
    "\n",
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Loc.corpus_path/'lenta.base.zip',\n",
    "    PROCESSED,\n",
    "    ['partition']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
