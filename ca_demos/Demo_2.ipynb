{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text fragmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This demo shows text fragmentation and retells post-processing with parallel corpus:\n",
    "- text fragmentation with localization (english, russian)\n",
    "- model retells post-processing\n",
    "- translating english retells to russian\n",
    "- writing valuable data to parallel corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text fragmentation with localization (english, russian)\n",
    "The FragmentsBuilder parses the text from book corpus into json-format file with: \n",
    "- prompt\n",
    "- text fragments of preset words limit\n",
    "- some info about text frame (like first word id and last word id in book corpus, chapter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ru_book', 'ru_retell', 'eng_book', 'eng_retell', 'ru_translate'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grammar_ru.corpus import CorpusBuilder, CorpusReader, ParallelCorpus\n",
    "from pathlib import Path\n",
    "\n",
    "parallel_corpus = ParallelCorpus(Path('files/parallel_corpus.zip'))\n",
    "toc = parallel_corpus.get_toc()\n",
    "toc.subcorpus_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_corpus = parallel_corpus.eng_book\n",
    "ru_corpus = parallel_corpus.ru_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragmentation of english and russian books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ca.book_fragments.fragments_builder import FragmentsBuilder\n",
    "from ca.book_fragments.localizators.ru_localizator import RussianLocalizator\n",
    "from ca.book_fragments.localizators.eng_localizator import EnglishLocalizator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame with id: 1d18fb7e-f905-4180-af6d-0a59aa60cd26, 123/123\r"
     ]
    }
   ],
   "source": [
    "eng_fragments_builder = FragmentsBuilder(\n",
    "    eng_corpus, \n",
    "    output_path='./files/fragments', \n",
    "    file_name=\"eng_crime_and_punishment_fragments\", \n",
    "    localizator=EnglishLocalizator()\n",
    ")\n",
    "\n",
    "eng_fragments_builder.construct_fragments_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame with id: cef9698c-465b-4c2f-9926-9cefe5bdc5de, 123/123\r"
     ]
    }
   ],
   "source": [
    "ru_fragments_builder = FragmentsBuilder(\n",
    "    ru_corpus, \n",
    "    output_path='./files/fragments', \n",
    "    file_name=\"ru_crime_and_punishment_fragments\", \n",
    "    localizator=RussianLocalizator(),\n",
    "    prompt='{}'\n",
    ")\n",
    "\n",
    "ru_fragments_builder.construct_fragments_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model retells post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model returns json file with retells and some log info, after that retells are cleared and prettified,\n",
    "then prepared texts are parsed into corresponding corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ca.book_fragments.utils.parse_retells_to_corpus import parse_retells_to_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'source\\\\retell\\\\eng\\\\eng_crime_and_punishment_fragments.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparse_retells_to_corpus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./files/fragments/eng_crime_and_punishment_fragments.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./source/retell/eng/eng_crime_and_punishment_fragments.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./files/eng_crime_and_punishment_retell.base.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\yura\\desktop\\repos\\grammar_ru\\ca\\book_fragments\\utils\\parse_retells_to_corpus.py:16\u001b[0m, in \u001b[0;36mparse_retells_to_corpus\u001b[1;34m(fragments_path, retells_path, corpus_path, separator)\u001b[0m\n\u001b[0;32m     13\u001b[0m corpus_writer \u001b[38;5;241m=\u001b[39m CorpusWriter(corpus_path)\n\u001b[0;32m     15\u001b[0m retells_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretells_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m retells_file:\n\u001b[0;32m     17\u001b[0m     retells_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(retells_file)\n\u001b[0;32m     19\u001b[0m fragments_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'source\\\\retell\\\\eng\\\\eng_crime_and_punishment_fragments.json'"
     ]
    }
   ],
   "source": [
    "parse_retells_to_corpus(\n",
    "    Path('./files/fragments/eng_crime_and_punishment_fragments.json'),\n",
    "    Path('./source/retell/eng/eng_crime_and_punishment_fragments.json'),\n",
    "    Path('./files/eng_crime_and_punishment_retell.base.zip'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_retells_to_corpus(\n",
    "    Path('./files/fragments/ru_crime_and_punishment_fragments.json'),\n",
    "    Path('./source/retell/ru/ru_crime_and_punishment_fragments.json'),\n",
    "    Path('./files/ru_crime_and_punishment_retell.base.zip'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_retell_reader = CorpusReader(Path('./files/ru_crime_and_punishment_retell.base.zip'))\n",
    "ru_retell = ru_retell_reader.get_toc().index\n",
    "ru_retell_reader.get_frames().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_retell_reader = CorpusReader(Path('./files/eng_crime_and_punishment_retell.base.zip'))\n",
    "eng_retell = eng_retell_reader.get_toc().index\n",
    "eng_retell_reader.get_toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for convenient parallel corpus assemblying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_relation(df_1,df_2,name_1,name_2):\n",
    "    rel_1 = pd.DataFrame({'file_1':df_1, 'file_2':df_2,'relation_name':f\"{name_1}_{name_2}\"})\n",
    "    rel_2 = pd.DataFrame({'file_1':df_2, 'file_2':df_1,'relation_name':f\"{name_2}_{name_1}\"})\n",
    "    rel = pd.concat([rel_1,rel_2])\n",
    "    return rel\n",
    "\n",
    "def add_dfs(name):\n",
    "    frames = list(name.get_frames())\n",
    "    dfs = dict(zip(name.get_toc().index,frames))\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record english and russian books corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_book_reader = CorpusReader(Path('./files/eng_crime_and_puhishment.base.zip'))\n",
    "eng_book_reader.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_book_reader = CorpusReader(Path('./files/ru_crime_and_puhishment.base.zip'))\n",
    "ru_book_reader.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(eng_book_reader),\n",
    "    \"eng_book\",\n",
    "    None)\n",
    "\n",
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(ru_book_reader),\n",
    "    \"ru_book\",\n",
    "    None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record english and russian retells, add relations to books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_retell_reader = CorpusReader(Path('./files/eng_crime_and_punishment_retell.base.zip'))\n",
    "eng_retell_reader.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_retell_reader = CorpusReader(Path('./files/ru_crime_and_punishment_retell.base.zip'))\n",
    "ru_retell_reader.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(eng_retell_reader),\n",
    "    \"eng_retell\",\n",
    "    add_relation(eng_book_reader.get_toc().index, eng_retell_reader.get_toc().index, \"eng_book\", \"eng_retell\"))\n",
    "\n",
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(ru_retell_reader),\n",
    "    \"ru_retell\",\n",
    "    add_relation(ru_book_reader.get_toc().index, ru_retell_reader.get_toc().index, \"ru_book\", \"ru_retell\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parallel_corpus = Path('./files/parallel_corpus.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add data with translated english retell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.ca.utils_translate import translate_subcorpus\n",
    "\n",
    "translate_subcorpus(path_parallel_corpus,\"eng_retell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, show parallel corpus contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CorpusReader(path_parallel_corpus)\n",
    "df = reader.get_toc()\n",
    "df.subcorpus_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# os.remove(Path('./files/eng_crime_and_puhishment.base.zip'))\n",
    "# os.remove(Path('./files/ru_crime_and_puhishment.base.zip'))\n",
    "os.remove(Path('./files/eng_crime_and_punishment_retell.base.zip'))\n",
    "os.remove(Path('./files/ru_crime_and_punishment_retell.base.zip'))\n",
    "os.remove(Path('./files/translate.base.zip'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
