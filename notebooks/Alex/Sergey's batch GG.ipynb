{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39dda17-d667-4b97-b0c4-e8dc8a5c3c1a",
   "metadata": {},
   "source": [
    "Адаптируем построение бандла из задачи поиска ошибки согласования рода к задаче поиска антецедентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433e8db-3a17-49ff-b43c-be9e2712b137",
   "metadata": {},
   "source": [
    "Посмотрим как работает CoreExtractor - сущность, которая по слову вернет все признаки. Умеет работать с любыми индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04c218ef-19f2-4ec6-bda9-10874a72cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from yo_fluq_ds import *\n",
    "from tg.common.ml import batched_training as bt\n",
    "from tg.common import DataBundle, Loc\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.ml.components.core_extractor.extractor import CoreExtractor\n",
    "from tg.grammar_ru.ml.components.plain_context_builder import PlainContextBuilder\n",
    "from tg.grammar_ru.ml.components.contextual_binding import ContextualBinding, ContextualNetworkType\n",
    "from tg.common.ml.batched_training import mirrors as btm\n",
    "from tg.common.ml.batched_training import Batcher\n",
    "from tg.grammar_ru.common import Separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "626fd51f-c7bf-4178-b988-24fde39ab4ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronoun_word_id</th>\n",
       "      <th>pronoun_sentence_id</th>\n",
       "      <th>candidate_word_id</th>\n",
       "      <th>candidate_sentence_id</th>\n",
       "      <th>candidate_distance</th>\n",
       "      <th>is_match</th>\n",
       "      <th>word_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514884</td>\n",
       "      <td>514880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514885</td>\n",
       "      <td>514880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903357</td>\n",
       "      <td>1903337</td>\n",
       "      <td>1903342</td>\n",
       "      <td>1903335</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101060</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837513</td>\n",
       "      <td>22837429</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101061</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837524</td>\n",
       "      <td>22837430</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101062</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837537</td>\n",
       "      <td>22837430</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101063</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837545</td>\n",
       "      <td>22837430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101064</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837547</td>\n",
       "      <td>22837430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101065 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pronoun_word_id  pronoun_sentence_id  candidate_word_id  \\\n",
       "sample_id                                                            \n",
       "0                        7                    0                  4   \n",
       "1                        7                    0                  5   \n",
       "2                   514887               514880             514884   \n",
       "3                   514887               514880             514885   \n",
       "4                  1903357              1903337            1903342   \n",
       "...                    ...                  ...                ...   \n",
       "101060            22837552             22837430           22837513   \n",
       "101061            22837552             22837430           22837524   \n",
       "101062            22837552             22837430           22837537   \n",
       "101063            22837552             22837430           22837545   \n",
       "101064            22837552             22837430           22837547   \n",
       "\n",
       "           candidate_sentence_id  candidate_distance  is_match  word_distance  \n",
       "sample_id                                                                      \n",
       "0                              0                   1         1              3  \n",
       "1                              0                   0         0              2  \n",
       "2                         514880                   1         1              3  \n",
       "3                         514880                   0         0              2  \n",
       "4                        1903335                   3         0             12  \n",
       "...                          ...                 ...       ...            ...  \n",
       "101060                  22837429                   4         0             33  \n",
       "101061                  22837430                   3         0             25  \n",
       "101062                  22837430                   2         0             14  \n",
       "101063                  22837430                   1         0              7  \n",
       "101064                  22837430                   0         0              5  \n",
       "\n",
       "[101065 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.ml.features import PyMorphyFeaturizer\n",
    "\n",
    "db = DataBundle.load(Loc.bundles_path/'antcd/wwd')\n",
    "db.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c682565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronoun_word_id</th>\n",
       "      <th>pronoun_sentence_id</th>\n",
       "      <th>candidate_word_id</th>\n",
       "      <th>candidate_sentence_id</th>\n",
       "      <th>candidate_distance</th>\n",
       "      <th>label</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514884</td>\n",
       "      <td>514880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514885</td>\n",
       "      <td>514880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903357</td>\n",
       "      <td>1903337</td>\n",
       "      <td>1903342</td>\n",
       "      <td>1903335</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011213</td>\n",
       "      <td>2010935</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011223</td>\n",
       "      <td>2010937</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011227</td>\n",
       "      <td>2010937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021283</td>\n",
       "      <td>2021249</td>\n",
       "      <td>2021253</td>\n",
       "      <td>2021248</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021283</td>\n",
       "      <td>2021249</td>\n",
       "      <td>2021263</td>\n",
       "      <td>2021248</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pronoun_word_id  pronoun_sentence_id  candidate_word_id  \\\n",
       "sample_id                                                            \n",
       "0                        7                    0                  4   \n",
       "1                        7                    0                  5   \n",
       "2                   514887               514880             514884   \n",
       "3                   514887               514880             514885   \n",
       "4                  1903357              1903337            1903342   \n",
       "...                    ...                  ...                ...   \n",
       "995                2011233              2010938            2011213   \n",
       "996                2011233              2010938            2011223   \n",
       "997                2011233              2010938            2011227   \n",
       "998                2021283              2021249            2021253   \n",
       "999                2021283              2021249            2021263   \n",
       "\n",
       "           candidate_sentence_id  candidate_distance  label  word_distance  \\\n",
       "sample_id                                                                    \n",
       "0                              0                   1      1              3   \n",
       "1                              0                   0      0              2   \n",
       "2                         514880                   1      1              3   \n",
       "3                         514880                   0      0              2   \n",
       "4                        1903335                   3      0             12   \n",
       "...                          ...                 ...    ...            ...   \n",
       "995                      2010935                   2      0             14   \n",
       "996                      2010937                   1      0              7   \n",
       "997                      2010937                   0      1              4   \n",
       "998                      2021248                   3      0             25   \n",
       "999                      2021248                   2      0             17   \n",
       "\n",
       "           split  \n",
       "sample_id         \n",
       "0           test  \n",
       "1          train  \n",
       "2           test  \n",
       "3           test  \n",
       "4          train  \n",
       "...          ...  \n",
       "995        train  \n",
       "996         test  \n",
       "997        train  \n",
       "998        train  \n",
       "999        train  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.ml.batched_training import train_display_test_split\n",
    "\n",
    "db.index = db.index.iloc[:1000]\n",
    "db.index = db.index.rename(columns={'is_match': 'label'})\n",
    "db.index['split'] = train_display_test_split(db.index)\n",
    "db.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bcbc1c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tg.common.ml.batched_training.data_bundle.IndexedDataBundle at 0x26e0daecd30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idb = IndexedDataBundle(db.index, db)\n",
    "idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fba59cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><span title=\"0\"\">Семь <span title=\"1\"\">книг <span title=\"2\"\">о <span title=\"3\"\">приключениях <span title=\"4\"\">Гарри <span title=\"5\"\">Поттера <span title=\"6\"\">и <span title=\"7\"\">его <span title=\"8\"\">друзей <span title=\"9\"\">из <span title=\"10\"\">школы <span title=\"11\"\">волшебников <span title=\"12\"\">«<span title=\"13\"\">Хогвартс<span title=\"14\"\">» <span title=\"15\"\">уже<span title=\"16\"\">, <span title=\"17\"\">наверное<span title=\"18\"\">, <span title=\"19\"\">не <span title=\"20\"\">нуждаются <span title=\"21\"\">в <span title=\"22\"\">рекламе <span title=\"23\"\">— <span title=\"24\"\">все <span title=\"25\"\">и <span title=\"26\"\">так <span title=\"27\"\">про <span title=\"28\"\">них <span title=\"29\"\">знают<span title=\"30\"\">. </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Separator.Viewer().tooltip(\"word_id\").to_html_display(\n",
    "    idb.bundle.src.loc[idb.bundle.src.sentence_id == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251a41-9daf-4fd3-a354-0b1033e41d97",
   "metadata": {},
   "source": [
    "CoreExtractor принимает список extractor'ов и применяет их к бандлу. Потом нужно подать его ContextualBinding. TODO да?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e46912",
   "metadata": {},
   "source": [
    "##### Пример CoreExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9762bb8-60af-42f0-b9fb-d029b374cc35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "core = CoreExtractor(join_column='pronoun_word_id')\n",
    "core.fit(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b925e63b-dd22-434e-8bee-22488e67463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymorphy_score</th>\n",
       "      <th>pymorphy_delta_score</th>\n",
       "      <th>pymorphy_alternatives</th>\n",
       "      <th>pymorphy_POS_NPRO</th>\n",
       "      <th>pymorphy_animacy_NULL</th>\n",
       "      <th>pymorphy_gender_masc</th>\n",
       "      <th>pymorphy_gender_femn</th>\n",
       "      <th>pymorphy_number_sing</th>\n",
       "      <th>pymorphy_case_accs</th>\n",
       "      <th>pymorphy_case_nomn</th>\n",
       "      <th>...</th>\n",
       "      <th>slovnet_morph_Voice_NULL</th>\n",
       "      <th>slovnet_morph_Degree_NULL</th>\n",
       "      <th>slovnet_morph_Foreign_NULL</th>\n",
       "      <th>slovnet_morph_Variant_NULL</th>\n",
       "      <th>slovnet_morph_Polarity_NULL</th>\n",
       "      <th>slovnet_syntax_relation_nmod</th>\n",
       "      <th>slovnet_syntax_relation_det</th>\n",
       "      <th>slovnet_syntax_relation_obj</th>\n",
       "      <th>slovnet_syntax_relation_nsubj</th>\n",
       "      <th>slovnet_syntax_relation_iobj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.908753</td>\n",
       "      <td>-0.877471</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pymorphy_score  pymorphy_delta_score  pymorphy_alternatives  \\\n",
       "sample_id                                                                \n",
       "0                0.039619              0.053981               0.247520   \n",
       "1                0.039619              0.053981               0.247520   \n",
       "2                0.039619              0.053981               0.247520   \n",
       "3                0.039619              0.053981               0.247520   \n",
       "4               -0.908753             -0.877471               0.097863   \n",
       "...                   ...                   ...                    ...   \n",
       "995              1.164046              0.228254              -3.433975   \n",
       "996              1.164046              0.228254              -3.433975   \n",
       "997              1.164046              0.228254              -3.433975   \n",
       "998              0.039619              0.053981               0.247520   \n",
       "999              0.039619              0.053981               0.247520   \n",
       "\n",
       "           pymorphy_POS_NPRO  pymorphy_animacy_NULL  pymorphy_gender_masc  \\\n",
       "sample_id                                                                   \n",
       "0                        1.0                    1.0                   1.0   \n",
       "1                        1.0                    1.0                   1.0   \n",
       "2                        1.0                    1.0                   1.0   \n",
       "3                        1.0                    1.0                   1.0   \n",
       "4                        1.0                    1.0                   0.0   \n",
       "...                      ...                    ...                   ...   \n",
       "995                      1.0                    1.0                   0.0   \n",
       "996                      1.0                    1.0                   0.0   \n",
       "997                      1.0                    1.0                   0.0   \n",
       "998                      1.0                    1.0                   1.0   \n",
       "999                      1.0                    1.0                   1.0   \n",
       "\n",
       "           pymorphy_gender_femn  pymorphy_number_sing  pymorphy_case_accs  \\\n",
       "sample_id                                                                   \n",
       "0                           0.0                   1.0                 1.0   \n",
       "1                           0.0                   1.0                 1.0   \n",
       "2                           0.0                   1.0                 1.0   \n",
       "3                           0.0                   1.0                 1.0   \n",
       "4                           1.0                   1.0                 1.0   \n",
       "...                         ...                   ...                 ...   \n",
       "995                         1.0                   1.0                 0.0   \n",
       "996                         1.0                   1.0                 0.0   \n",
       "997                         1.0                   1.0                 0.0   \n",
       "998                         0.0                   1.0                 1.0   \n",
       "999                         0.0                   1.0                 1.0   \n",
       "\n",
       "           pymorphy_case_nomn  ...  slovnet_morph_Voice_NULL  \\\n",
       "sample_id                      ...                             \n",
       "0                         0.0  ...                       1.0   \n",
       "1                         0.0  ...                       1.0   \n",
       "2                         0.0  ...                       1.0   \n",
       "3                         0.0  ...                       1.0   \n",
       "4                         0.0  ...                       1.0   \n",
       "...                       ...  ...                       ...   \n",
       "995                       0.0  ...                       1.0   \n",
       "996                       0.0  ...                       1.0   \n",
       "997                       0.0  ...                       1.0   \n",
       "998                       0.0  ...                       1.0   \n",
       "999                       0.0  ...                       1.0   \n",
       "\n",
       "           slovnet_morph_Degree_NULL  slovnet_morph_Foreign_NULL  \\\n",
       "sample_id                                                          \n",
       "0                                1.0                         1.0   \n",
       "1                                1.0                         1.0   \n",
       "2                                1.0                         1.0   \n",
       "3                                1.0                         1.0   \n",
       "4                                1.0                         1.0   \n",
       "...                              ...                         ...   \n",
       "995                              1.0                         1.0   \n",
       "996                              1.0                         1.0   \n",
       "997                              1.0                         1.0   \n",
       "998                              1.0                         1.0   \n",
       "999                              1.0                         1.0   \n",
       "\n",
       "           slovnet_morph_Variant_NULL  slovnet_morph_Polarity_NULL  \\\n",
       "sample_id                                                            \n",
       "0                                 1.0                          1.0   \n",
       "1                                 1.0                          1.0   \n",
       "2                                 1.0                          1.0   \n",
       "3                                 1.0                          1.0   \n",
       "4                                 1.0                          1.0   \n",
       "...                               ...                          ...   \n",
       "995                               1.0                          1.0   \n",
       "996                               1.0                          1.0   \n",
       "997                               1.0                          1.0   \n",
       "998                               1.0                          1.0   \n",
       "999                               1.0                          1.0   \n",
       "\n",
       "           slovnet_syntax_relation_nmod  slovnet_syntax_relation_det  \\\n",
       "sample_id                                                              \n",
       "0                                   1.0                          0.0   \n",
       "1                                   1.0                          0.0   \n",
       "2                                   1.0                          0.0   \n",
       "3                                   1.0                          0.0   \n",
       "4                                   0.0                          1.0   \n",
       "...                                 ...                          ...   \n",
       "995                                 1.0                          0.0   \n",
       "996                                 1.0                          0.0   \n",
       "997                                 1.0                          0.0   \n",
       "998                                 1.0                          0.0   \n",
       "999                                 1.0                          0.0   \n",
       "\n",
       "           slovnet_syntax_relation_obj  slovnet_syntax_relation_nsubj  \\\n",
       "sample_id                                                               \n",
       "0                                  0.0                            0.0   \n",
       "1                                  0.0                            0.0   \n",
       "2                                  0.0                            0.0   \n",
       "3                                  0.0                            0.0   \n",
       "4                                  0.0                            0.0   \n",
       "...                                ...                            ...   \n",
       "995                                0.0                            0.0   \n",
       "996                                0.0                            0.0   \n",
       "997                                0.0                            0.0   \n",
       "998                                0.0                            0.0   \n",
       "999                                0.0                            0.0   \n",
       "\n",
       "           slovnet_syntax_relation_iobj  \n",
       "sample_id                                \n",
       "0                                   0.0  \n",
       "1                                   0.0  \n",
       "2                                   0.0  \n",
       "3                                   0.0  \n",
       "4                                   0.0  \n",
       "...                                 ...  \n",
       "995                                 0.0  \n",
       "996                                 0.0  \n",
       "997                                 0.0  \n",
       "998                                 0.0  \n",
       "999                                 0.0  \n",
       "\n",
       "[1000 rows x 48 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted = core.extract(idb)\n",
    "extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f5e69-8534-446a-aef2-ab8215001720",
   "metadata": {},
   "source": [
    "* Для каждого слова получили все признаки из pymorphy, slovnet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08039c7d-48b0-4d7a-b5b1-128e1c93ede7",
   "metadata": {},
   "source": [
    "* Нам необходим контекст слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15527c-77cd-4b6c-8bd8-78e2c825c932",
   "metadata": {},
   "source": [
    "Будем использовать `PlainContextBuilder`.  Он построит двойной индекс.\n",
    "\n",
    "* хотим исключить само слово из контекста, поэтому `include_zero_offset=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd869e7c",
   "metadata": {},
   "source": [
    "#### Пример PlainContextBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fb1077c-4498-448a-af52-32a64dfd1de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>1903357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <th>2</th>\n",
       "      <td>2011235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">998</th>\n",
       "      <th>1</th>\n",
       "      <td>2021284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">999</th>\n",
       "      <th>1</th>\n",
       "      <td>2021284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4027 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  another_word_id\n",
       "sample_id offset                 \n",
       "0         0                     7\n",
       "1         0                     7\n",
       "2         0                514887\n",
       "3         0                514887\n",
       "4         0               1903357\n",
       "...                           ...\n",
       "997       2               2011235\n",
       "998       1               2021284\n",
       "          2               2021285\n",
       "999       1               2021284\n",
       "          2               2021285\n",
       "\n",
       "[4027 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronoun_pcb = PlainContextBuilder(include_zero_offset=True,\n",
    "                                  left_to_right_contexts_proportion=0.5)\n",
    "pronoun_pcb.sentence_id_column_name = 'pronoun_sentence_id'\n",
    "pronoun_pcb.word_id_column_name = 'pronoun_word_id'\n",
    "pronoun_contexts = pronoun_pcb.build_context(idb, context_size=5)\n",
    "pronoun_contexts  # TODO у некоторых только offsset == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d3e5494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>514886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>514885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>514888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>514889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  offset  another_word_id\n",
       "2             2       0           514887\n",
       "1004          2      -1           514886\n",
       "1005          2      -2           514885\n",
       "2031          2       1           514888\n",
       "2032          2       2           514889"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = pronoun_contexts.reset_index()\n",
    "cdf.loc[cdf.sample_id == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394440ba",
   "metadata": {},
   "source": [
    "#### WordContextAssemblyPoint (~ ContextualBinding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c68dbb",
   "metadata": {},
   "source": [
    "Задача AssemblyPoint'a (он же ContextualBinding) - порождать экстракторами батчи в том виде, в котором они будут приняты сетью. Для LSTM будет 3d-тензор. Для Plain-сети будет плоский датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "395fd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_context(pcb):\n",
    "    return ContextualBinding(\n",
    "    name='plain_context',\n",
    "    context_length=3,\n",
    "    network_type=ContextualNetworkType.Plain,\n",
    "    hidden_size=[30],\n",
    "    context_builder=pcb,\n",
    "    extractor=CoreExtractor(join_column='another_word_id'),\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "pronoun_plain_context = get_plain_context(pronoun_pcb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92aa50",
   "metadata": {},
   "source": [
    "**Пояснение:**\n",
    "По умолчанию CoreExtractor пытается мерджить по word_id. В нашем случае CoreExtractor отработает после создания PlainContextBuilder'ом двойного индекса. \n",
    "Для добавления признаков слов из контекста будем join'ить по столбцу another_word_id. Поэтому join_column='another_word_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae35c19",
   "metadata": {},
   "source": [
    "Для создания согласованных экстракторов и сетей у AssemblyPoint есть методы create_extractor и create_network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc9aac",
   "metadata": {},
   "source": [
    "У такой сети на последнем слое hidden_size нейронов. Ее выход можно подать в другую сеть, которая будет выдавать вероятности классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afeb414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_context_extractor = pronoun_plain_context.create_extractor(task=None, bundle=idb)\n",
    "pronoun_context_extractor.fit(idb)\n",
    "# not_batch = core_extractor.extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab4bf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_context_extractor = candidate_plain_context.create_extractor(task=None, bundle=idb)\n",
    "candidate_context_extractor.fit(idb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa95cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = pronoun_plain_context.create_network_factory(\n",
    "    task=None, input=None)  # None это ок. это legacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8a14c",
   "metadata": {},
   "source": [
    "#### Batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5c17e",
   "metadata": {},
   "source": [
    "Иногда нам нужны фичи контекстов нескольких слов. Например, в задаче поиска антецедентов это местоимение и два существительных - потенциальные антецеденты. Для каждого из этих слов создадим экстрактор (для каждого экстрактора будет отдельная голова нейросети). Batcher примет список этих экстракторов и создаст батч.\n",
    "\n",
    "`+` нам понадобится экстрагировать лейблы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "59f8f8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label\n",
       "sample_id       \n",
       "0              1\n",
       "1              0\n",
       "2              1\n",
       "3              0\n",
       "4              0\n",
       "5              0\n",
       "6              1\n",
       "7              0\n",
       "8              0\n",
       "9              0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import Conventions\n",
    "from tg.common.ml import dft\n",
    "# экстрагирует лейблы. Получается one-hot df. Лейблы пойдут в loss function.\n",
    "\n",
    "\n",
    "def get_binary_label_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=None))\n",
    "    return label_extractor\n",
    "\n",
    "\n",
    "def test_extractor(extractor, bundle):\n",
    "    extractor.fit(bundle)\n",
    "    return extractor.extract(bundle)\n",
    "\n",
    "test_extractor(get_binary_label_extractor(), idb).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a3b06cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batcher = Batcher(batch_size=1000, extractors=[\n",
    "                  pronoun_context_extractor, get_binary_extractor()])\n",
    "batch = batcher.fit_extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b9addb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 30])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = factory.create_network(task=None, input=batch)\n",
    "network(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d0281",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++\n",
    "+++++++++++++++++++++++\n",
    "+++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01e69b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml.batched_training.torch.networks.extracting_network import FeedForwardNetwork\n",
    "from tg.common.ml.batched_training.torch.networks.simple_networks import FullyConnectedNetwork, ParallelNetwork\n",
    "\n",
    "def get_head_factory(sentence_id_column_name, word_id_column_name):\n",
    "    pcb = PlainContextBuilder(include_zero_offset=True, left_to_right_contexts_proportion=0.5)\n",
    "    pcb.sentence_id_column_name = sentence_id_column_name\n",
    "    pcb.word_id_column_name = word_id_column_name\n",
    "    plain_context = ContextualBinding(\n",
    "        name='plain_context',\n",
    "        context_length=3,\n",
    "        network_type=ContextualNetworkType.Plain,\n",
    "        hidden_size=[30],\n",
    "        context_builder=pcb,\n",
    "        extractor=CoreExtractor(join_column='another_word_id'),\n",
    "        debug=False\n",
    "    )\n",
    "    return plain_context.create_network_factory(task=None, input=None)\n",
    "\n",
    "\n",
    "class HeadsUnionNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 sizes: List[int],\n",
    "                 heads,\n",
    "                 outs,\n",
    "                 output: Union[None, torch.Tensor, int] = None):\n",
    "        super(HeadsUnionNetwork, self).__init__()\n",
    "        heads_forward_networks = dict()\n",
    "        for i in range(len(heads)):\n",
    "            fully_connected = FullyConnectedNetwork(sizes=[3], input=outs[i].shape[1], output=output)\n",
    "            heads_forward_networks[str(i)] = FeedForwardNetwork(heads[i], fully_connected, torch.nn.Softmax(dim=1))\n",
    "        parallel_network = ParallelNetwork()\n",
    "        parallel_network.networks = torch.nn.ModuleDict(heads_forward_networks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        heads_outputs = parallel_network(input)\n",
    "        for output in heads_outputs.values():\n",
    "            #aggregate results\n",
    "            print(output)\n",
    "    \n",
    "\n",
    "class MultiheadNetworkFactory:\n",
    "    def __init__(self, *head_factories):\n",
    "        self.head_factories = [*head_factories]\n",
    "\n",
    "    def create_network(self, task, input):  # input is batch ~ sample\n",
    "        heads = [f.create_network(task=None, input=input) for f in self.head_factories]\n",
    "        outs = [h(input) for h in heads]\n",
    "\n",
    "        return HeadsUnionNetwork(sizes=[3], heads=heads, outs=outs, output=input['label'].shape[1])\n",
    "\n",
    "pronoun_head_factory = get_head_factory('pronoun_sentence_id', 'pronoun_word_id')\n",
    "candidate_head_factory = get_head_factory('candidate_sentence_id', 'candidate_word_id')\n",
    "network_factory = MultiheadNetworkFactory(pronoun_head_factory, candidate_head_factory)\n",
    "assembled_network = network_factory.create_network(task=None, input=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b515482",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'split'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model(network_factory)\n\u001b[0;32m      8\u001b[0m task \u001b[38;5;241m=\u001b[39m ClassificationTask()\n\u001b[1;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\training_core\\arch.py:78\u001b[0m, in \u001b[0;36mAbstractTrainingTask.run\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any):\n\u001b[0;32m     77\u001b[0m     env \u001b[38;5;241m=\u001b[39m InMemoryTrainingEnvironment()\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\grammar_ru\\ml\\components\\training_task_factory\\torch_task_factory.py:47\u001b[0m, in \u001b[0;36mTaskFactory.run_with_environment\u001b[1;34m(self, data, env)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_task(data, env)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:354\u001b[0m, in \u001b[0;36mBatchedTrainingTask.run_with_environment\u001b[1;34m(self, _bundle, env)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, _bundle: Union[\u001b[38;5;28mstr\u001b[39m, Path, DataBundle], env: Optional[TrainingEnvironment] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 354\u001b[0m     temp_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization completed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    357\u001b[0m     temp_data\u001b[38;5;241m.\u001b[39mtrain_bundle \u001b[38;5;241m=\u001b[39m temp_data\u001b[38;5;241m.\u001b[39moriginal_ibundle\u001b[38;5;241m.\u001b[39mchange_index(temp_data\u001b[38;5;241m.\u001b[39msplit\u001b[38;5;241m.\u001b[39mtrain)\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:171\u001b[0m, in \u001b[0;36mBatchedTrainingTask._prepare_all\u001b[1;34m(self, bundle, env)\u001b[0m\n\u001b[0;32m    168\u001b[0m Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreprocessing bundle by batcher\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatcher\u001b[38;5;241m.\u001b[39mpreprocess_bundle(ibundle)\n\u001b[1;32m--> 171\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mibundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m split_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplits: train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(split\u001b[38;5;241m.\u001b[39mtrain)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m split\u001b[38;5;241m.\u001b[39mtests\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[0;32m    173\u001b[0m Logger\u001b[38;5;241m.\u001b[39minfo(split_msg)\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:112\u001b[0m, in \u001b[0;36mBatchedTrainingTask._get_split\u001b[1;34m(self, ibundle)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_split\u001b[39m(\u001b[38;5;28mself\u001b[39m, ibundle: IndexedDataBundle):\n\u001b[0;32m    111\u001b[0m     initial_split \u001b[38;5;241m=\u001b[39m DataFrameSplit(ibundle\u001b[38;5;241m.\u001b[39mindex_frame, [], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 112\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplitter must provide exactly one split in case of batch training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\training_core\\splitter.py:264\u001b[0m, in \u001b[0;36mPredefinedSplitter.__call__\u001b[1;34m(self, dfs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dfs):\n\u001b[0;32m    263\u001b[0m     rdfs \u001b[38;5;241m=\u001b[39m dfs\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m--> 264\u001b[0m     rdfs\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m dfs\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_values)]\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m    265\u001b[0m     rdfs\u001b[38;5;241m.\u001b[39mtests \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_values:\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'split'"
     ]
    }
   ],
   "source": [
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add_sklearn(roc_auc_score)\n",
    "        self.instantiate_default_task(epoch_count=10, batch_size=1000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(data, [pronoun_context_extractor, get_binary_label_extractor()])\n",
    "        self.setup_model(network_factory)\n",
    "        \n",
    "task = ClassificationTask()\n",
    "result = task.run(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc242c8a",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0056c0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch_indices = batcher.get_mini_batch_indices(mini_batch_size = 10, batch = batch)\n",
    "mini_batch = batcher.get_mini_batch(index = mini_batch_indices[0], batch = batch)\n",
    "mini_batch['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c781561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8770, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, input)\n",
    "output.backward()\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ffa2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer):\n",
    "    for mini_batch_num, mini_batch_index in enumerate(mini_batch_indices):\n",
    "        mini_batch = batcher.get_mini_batch(index = mini_batch_indices[mini_batch_num], batch = batch)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(mini_batch)\n",
    "        loss = loss_fn(pred, torch.tensor(mini_batch['label'].values, dtype=torch.float32))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{num_batches:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cf4481e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43massembled_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\torch\\optim\\sgd.py:105\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py:49\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     47\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     51\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "optimizer = torch.optim.SGD(assembled_network.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(assembled_network, loss, optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15015434",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f89d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = assembled_network(batch)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ClassificationNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, sample):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(sample['features'].shape[1], hidden_size)\n",
    "        self.output = torch.nn.Linear(hidden_size, sample['label'].shape[1])\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input['features']\n",
    "        X = torch.tensor(X.astype(float).values).float()\n",
    "        X = self.hidden(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        X = self.output(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml import dft\n",
    "\n",
    "\n",
    "class MulticlassMetrics(bt.Metric):\n",
    "    def __init__(self, add_accuracy=True, add_rating=False):\n",
    "        self.add_accuracy = add_accuracy\n",
    "        self.add_rating = add_rating\n",
    "\n",
    "    def get_names(self):\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append('accuracy')\n",
    "        if self.add_rating:\n",
    "            result.append('rating')\n",
    "        return result\n",
    "\n",
    "    def measure(self, df, _):\n",
    "        prefix = 'true_label_'\n",
    "        labels = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix):\n",
    "                labels.append(c.replace(prefix, ''))\n",
    "\n",
    "        def ustack(df, prefix, cols, name):\n",
    "            df = df[[prefix+c for c in cols]]\n",
    "            df.columns = [c for c in cols]\n",
    "            df = df.unstack().to_frame(name)\n",
    "            return df\n",
    "\n",
    "        predicted = ustack(df, 'predicted_label_', labels, 'predicted')\n",
    "        true = ustack(df, 'true_label_', labels, 'true')\n",
    "        df = predicted.merge(true, left_index=True,\n",
    "                             right_index=True).reset_index()\n",
    "        df.columns = ['label', 'sample', 'predicted', 'true']\n",
    "        df = df.feed(fluq.add_ordering_column(\n",
    "            'sample', ('predicted', False), 'predicted_rating'))\n",
    "\n",
    "        match = (df.loc[df.predicted_rating ==\n",
    "                 0].set_index('sample').true > 0.5)\n",
    "        rating = df.loc[df.true > 0.5].set_index('sample').predicted_rating\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append(match.mean())\n",
    "        if self.add_rating:\n",
    "            result.append(rating.mean())\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13188570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                       )\n",
    "    return label_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add(MulticlassMetrics())  # TODO epoch_count=20\n",
    "        self.instantiate_default_task(\n",
    "            epoch_count=1, batch_size=10000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(\n",
    "            # data, [get_feature_extractor(), get_multilabel_extractor()])\n",
    "            data, [core, get_multilabel_extractor()])\n",
    "        self.setup_model(lambda _, sample: ClassificationNetwork(\n",
    "            20, sample), learning_rate=1)\n",
    "\n",
    "\n",
    "task = ClassificationTask()\n",
    "idb = IndexedDataBundle(db.index, db)\n",
    "result = task.run(idb)\n",
    "# pd.DataFrame(result['output']['history']).set_index('iteration').plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f9e0f",
   "metadata": {},
   "source": [
    "setup_butcher принимает экстракторы. Передадим core? или завернем его в get_feature_extractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce965d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
