{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39dda17-d667-4b97-b0c4-e8dc8a5c3c1a",
   "metadata": {},
   "source": [
    "Адаптируем построение бандла из задачи поиска ошибки согласования рода к задаче поиска антецедентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433e8db-3a17-49ff-b43c-be9e2712b137",
   "metadata": {},
   "source": [
    "Посмотрим как работает CoreExtractor - сущность, которая по слову вернет все признаки. Умеет работать с любыми индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c218ef-19f2-4ec6-bda9-10874a72cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from yo_fluq_ds import *\n",
    "from tg.common.ml import batched_training as bt\n",
    "from tg.common import DataBundle, Loc\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.ml.components.core_extractor.extractor import CoreExtractor\n",
    "from tg.grammar_ru.ml.components.plain_context_builder import PlainContextBuilder\n",
    "from tg.grammar_ru.ml.components.contextual_binding import ContextualBinding, ContextualNetworkType\n",
    "from tg.common.ml.batched_training import mirrors as btm\n",
    "from tg.common.ml.batched_training import Batcher\n",
    "from tg.grammar_ru.common import Separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626fd51f-c7bf-4178-b988-24fde39ab4ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronoun_word_id</th>\n",
       "      <th>pronoun_sentence_id</th>\n",
       "      <th>candidate_word_id</th>\n",
       "      <th>candidate_sentence_id</th>\n",
       "      <th>candidate_distance</th>\n",
       "      <th>is_match</th>\n",
       "      <th>word_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514884</td>\n",
       "      <td>514880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514885</td>\n",
       "      <td>514880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903357</td>\n",
       "      <td>1903337</td>\n",
       "      <td>1903342</td>\n",
       "      <td>1903335</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101060</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837513</td>\n",
       "      <td>22837429</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101061</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837524</td>\n",
       "      <td>22837430</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101062</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837537</td>\n",
       "      <td>22837430</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101063</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837545</td>\n",
       "      <td>22837430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101064</th>\n",
       "      <td>22837552</td>\n",
       "      <td>22837430</td>\n",
       "      <td>22837547</td>\n",
       "      <td>22837430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101065 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pronoun_word_id  pronoun_sentence_id  candidate_word_id  \\\n",
       "sample_id                                                            \n",
       "0                        7                    0                  4   \n",
       "1                        7                    0                  5   \n",
       "2                   514887               514880             514884   \n",
       "3                   514887               514880             514885   \n",
       "4                  1903357              1903337            1903342   \n",
       "...                    ...                  ...                ...   \n",
       "101060            22837552             22837430           22837513   \n",
       "101061            22837552             22837430           22837524   \n",
       "101062            22837552             22837430           22837537   \n",
       "101063            22837552             22837430           22837545   \n",
       "101064            22837552             22837430           22837547   \n",
       "\n",
       "           candidate_sentence_id  candidate_distance  is_match  word_distance  \n",
       "sample_id                                                                      \n",
       "0                              0                   1         1              3  \n",
       "1                              0                   0         0              2  \n",
       "2                         514880                   1         1              3  \n",
       "3                         514880                   0         0              2  \n",
       "4                        1903335                   3         0             12  \n",
       "...                          ...                 ...       ...            ...  \n",
       "101060                  22837429                   4         0             33  \n",
       "101061                  22837430                   3         0             25  \n",
       "101062                  22837430                   2         0             14  \n",
       "101063                  22837430                   1         0              7  \n",
       "101064                  22837430                   0         0              5  \n",
       "\n",
       "[101065 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.ml.features import PyMorphyFeaturizer\n",
    "\n",
    "db = DataBundle.load(Loc.bundles_path/'antcd/wwd')\n",
    "db.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c682565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronoun_word_id</th>\n",
       "      <th>pronoun_sentence_id</th>\n",
       "      <th>candidate_word_id</th>\n",
       "      <th>candidate_sentence_id</th>\n",
       "      <th>candidate_distance</th>\n",
       "      <th>label</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514884</td>\n",
       "      <td>514880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514887</td>\n",
       "      <td>514880</td>\n",
       "      <td>514885</td>\n",
       "      <td>514880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903357</td>\n",
       "      <td>1903337</td>\n",
       "      <td>1903342</td>\n",
       "      <td>1903335</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011213</td>\n",
       "      <td>2010935</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011223</td>\n",
       "      <td>2010937</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2011233</td>\n",
       "      <td>2010938</td>\n",
       "      <td>2011227</td>\n",
       "      <td>2010937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021283</td>\n",
       "      <td>2021249</td>\n",
       "      <td>2021253</td>\n",
       "      <td>2021248</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021283</td>\n",
       "      <td>2021249</td>\n",
       "      <td>2021263</td>\n",
       "      <td>2021248</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pronoun_word_id  pronoun_sentence_id  candidate_word_id  \\\n",
       "sample_id                                                            \n",
       "0                        7                    0                  4   \n",
       "1                        7                    0                  5   \n",
       "2                   514887               514880             514884   \n",
       "3                   514887               514880             514885   \n",
       "4                  1903357              1903337            1903342   \n",
       "...                    ...                  ...                ...   \n",
       "995                2011233              2010938            2011213   \n",
       "996                2011233              2010938            2011223   \n",
       "997                2011233              2010938            2011227   \n",
       "998                2021283              2021249            2021253   \n",
       "999                2021283              2021249            2021263   \n",
       "\n",
       "           candidate_sentence_id  candidate_distance  label  word_distance  \\\n",
       "sample_id                                                                    \n",
       "0                              0                   1      1              3   \n",
       "1                              0                   0      0              2   \n",
       "2                         514880                   1      1              3   \n",
       "3                         514880                   0      0              2   \n",
       "4                        1903335                   3      0             12   \n",
       "...                          ...                 ...    ...            ...   \n",
       "995                      2010935                   2      0             14   \n",
       "996                      2010937                   1      0              7   \n",
       "997                      2010937                   0      1              4   \n",
       "998                      2021248                   3      0             25   \n",
       "999                      2021248                   2      0             17   \n",
       "\n",
       "             split  \n",
       "sample_id           \n",
       "0            train  \n",
       "1             test  \n",
       "2            train  \n",
       "3          display  \n",
       "4            train  \n",
       "...            ...  \n",
       "995        display  \n",
       "996           test  \n",
       "997          train  \n",
       "998        display  \n",
       "999           test  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.common.ml.batched_training import train_display_test_split\n",
    "\n",
    "db.index = db.index.iloc[:1000]\n",
    "db.index = db.index.rename(columns={'is_match': 'label'})\n",
    "db.index['split'] = train_display_test_split(db.index)\n",
    "db.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbc1c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tg.common.ml.batched_training.data_bundle.IndexedDataBundle at 0x1ab911ddb20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idb = IndexedDataBundle(db.index, db)\n",
    "idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba59cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><span title=\"0\"\">Семь <span title=\"1\"\">книг <span title=\"2\"\">о <span title=\"3\"\">приключениях <span title=\"4\"\">Гарри <span title=\"5\"\">Поттера <span title=\"6\"\">и <span title=\"7\"\">его <span title=\"8\"\">друзей <span title=\"9\"\">из <span title=\"10\"\">школы <span title=\"11\"\">волшебников <span title=\"12\"\">«<span title=\"13\"\">Хогвартс<span title=\"14\"\">» <span title=\"15\"\">уже<span title=\"16\"\">, <span title=\"17\"\">наверное<span title=\"18\"\">, <span title=\"19\"\">не <span title=\"20\"\">нуждаются <span title=\"21\"\">в <span title=\"22\"\">рекламе <span title=\"23\"\">— <span title=\"24\"\">все <span title=\"25\"\">и <span title=\"26\"\">так <span title=\"27\"\">про <span title=\"28\"\">них <span title=\"29\"\">знают<span title=\"30\"\">. </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Separator.Viewer().tooltip(\"word_id\").to_html_display(\n",
    "    idb.bundle.src.loc[idb.bundle.src.sentence_id == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251a41-9daf-4fd3-a354-0b1033e41d97",
   "metadata": {},
   "source": [
    "CoreExtractor принимает список extractor'ов и применяет их к бандлу. Потом нужно подать его ContextualBinding. TODO да?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e46912",
   "metadata": {},
   "source": [
    "##### Пример CoreExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9762bb8-60af-42f0-b9fb-d029b374cc35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:15:05.981907+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-06 08:15:06.293988+00:00 INFO: Success\n",
      "2022-12-06 08:15:06.294989+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-06 08:15:06.583161+00:00 INFO: Success\n",
      "2022-12-06 08:15:06.583161+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-06 08:15:06.824898+00:00 INFO: Success\n",
      "2022-12-06 08:15:06.825903+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-06 08:15:06.828899+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n",
      "2022-12-06 08:15:06.831901+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-06 08:15:06.834903+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n"
     ]
    }
   ],
   "source": [
    "core = CoreExtractor(join_column='pronoun_word_id')\n",
    "core.fit(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b925e63b-dd22-434e-8bee-22488e67463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pymorphy_score</th>\n",
       "      <th>pymorphy_delta_score</th>\n",
       "      <th>pymorphy_alternatives</th>\n",
       "      <th>pymorphy_POS_NPRO</th>\n",
       "      <th>pymorphy_animacy_NULL</th>\n",
       "      <th>pymorphy_gender_masc</th>\n",
       "      <th>pymorphy_gender_femn</th>\n",
       "      <th>pymorphy_number_sing</th>\n",
       "      <th>pymorphy_case_accs</th>\n",
       "      <th>pymorphy_case_nomn</th>\n",
       "      <th>...</th>\n",
       "      <th>slovnet_morph_Voice_NULL</th>\n",
       "      <th>slovnet_morph_Degree_NULL</th>\n",
       "      <th>slovnet_morph_Foreign_NULL</th>\n",
       "      <th>slovnet_morph_Variant_NULL</th>\n",
       "      <th>slovnet_morph_Polarity_NULL</th>\n",
       "      <th>slovnet_syntax_relation_nmod</th>\n",
       "      <th>slovnet_syntax_relation_det</th>\n",
       "      <th>slovnet_syntax_relation_obj</th>\n",
       "      <th>slovnet_syntax_relation_nsubj</th>\n",
       "      <th>slovnet_syntax_relation_iobj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.908753</td>\n",
       "      <td>-0.877471</td>\n",
       "      <td>0.097863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.164046</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>-3.433975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.247520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pymorphy_score  pymorphy_delta_score  pymorphy_alternatives  \\\n",
       "sample_id                                                                \n",
       "0                0.039619              0.053981               0.247520   \n",
       "1                0.039619              0.053981               0.247520   \n",
       "2                0.039619              0.053981               0.247520   \n",
       "3                0.039619              0.053981               0.247520   \n",
       "4               -0.908753             -0.877471               0.097863   \n",
       "...                   ...                   ...                    ...   \n",
       "995              1.164046              0.228254              -3.433975   \n",
       "996              1.164046              0.228254              -3.433975   \n",
       "997              1.164046              0.228254              -3.433975   \n",
       "998              0.039619              0.053981               0.247520   \n",
       "999              0.039619              0.053981               0.247520   \n",
       "\n",
       "           pymorphy_POS_NPRO  pymorphy_animacy_NULL  pymorphy_gender_masc  \\\n",
       "sample_id                                                                   \n",
       "0                        1.0                    1.0                   1.0   \n",
       "1                        1.0                    1.0                   1.0   \n",
       "2                        1.0                    1.0                   1.0   \n",
       "3                        1.0                    1.0                   1.0   \n",
       "4                        1.0                    1.0                   0.0   \n",
       "...                      ...                    ...                   ...   \n",
       "995                      1.0                    1.0                   0.0   \n",
       "996                      1.0                    1.0                   0.0   \n",
       "997                      1.0                    1.0                   0.0   \n",
       "998                      1.0                    1.0                   1.0   \n",
       "999                      1.0                    1.0                   1.0   \n",
       "\n",
       "           pymorphy_gender_femn  pymorphy_number_sing  pymorphy_case_accs  \\\n",
       "sample_id                                                                   \n",
       "0                           0.0                   1.0                 1.0   \n",
       "1                           0.0                   1.0                 1.0   \n",
       "2                           0.0                   1.0                 1.0   \n",
       "3                           0.0                   1.0                 1.0   \n",
       "4                           1.0                   1.0                 1.0   \n",
       "...                         ...                   ...                 ...   \n",
       "995                         1.0                   1.0                 0.0   \n",
       "996                         1.0                   1.0                 0.0   \n",
       "997                         1.0                   1.0                 0.0   \n",
       "998                         0.0                   1.0                 1.0   \n",
       "999                         0.0                   1.0                 1.0   \n",
       "\n",
       "           pymorphy_case_nomn  ...  slovnet_morph_Voice_NULL  \\\n",
       "sample_id                      ...                             \n",
       "0                         0.0  ...                       1.0   \n",
       "1                         0.0  ...                       1.0   \n",
       "2                         0.0  ...                       1.0   \n",
       "3                         0.0  ...                       1.0   \n",
       "4                         0.0  ...                       1.0   \n",
       "...                       ...  ...                       ...   \n",
       "995                       0.0  ...                       1.0   \n",
       "996                       0.0  ...                       1.0   \n",
       "997                       0.0  ...                       1.0   \n",
       "998                       0.0  ...                       1.0   \n",
       "999                       0.0  ...                       1.0   \n",
       "\n",
       "           slovnet_morph_Degree_NULL  slovnet_morph_Foreign_NULL  \\\n",
       "sample_id                                                          \n",
       "0                                1.0                         1.0   \n",
       "1                                1.0                         1.0   \n",
       "2                                1.0                         1.0   \n",
       "3                                1.0                         1.0   \n",
       "4                                1.0                         1.0   \n",
       "...                              ...                         ...   \n",
       "995                              1.0                         1.0   \n",
       "996                              1.0                         1.0   \n",
       "997                              1.0                         1.0   \n",
       "998                              1.0                         1.0   \n",
       "999                              1.0                         1.0   \n",
       "\n",
       "           slovnet_morph_Variant_NULL  slovnet_morph_Polarity_NULL  \\\n",
       "sample_id                                                            \n",
       "0                                 1.0                          1.0   \n",
       "1                                 1.0                          1.0   \n",
       "2                                 1.0                          1.0   \n",
       "3                                 1.0                          1.0   \n",
       "4                                 1.0                          1.0   \n",
       "...                               ...                          ...   \n",
       "995                               1.0                          1.0   \n",
       "996                               1.0                          1.0   \n",
       "997                               1.0                          1.0   \n",
       "998                               1.0                          1.0   \n",
       "999                               1.0                          1.0   \n",
       "\n",
       "           slovnet_syntax_relation_nmod  slovnet_syntax_relation_det  \\\n",
       "sample_id                                                              \n",
       "0                                   1.0                          0.0   \n",
       "1                                   1.0                          0.0   \n",
       "2                                   1.0                          0.0   \n",
       "3                                   1.0                          0.0   \n",
       "4                                   0.0                          1.0   \n",
       "...                                 ...                          ...   \n",
       "995                                 1.0                          0.0   \n",
       "996                                 1.0                          0.0   \n",
       "997                                 1.0                          0.0   \n",
       "998                                 1.0                          0.0   \n",
       "999                                 1.0                          0.0   \n",
       "\n",
       "           slovnet_syntax_relation_obj  slovnet_syntax_relation_nsubj  \\\n",
       "sample_id                                                               \n",
       "0                                  0.0                            0.0   \n",
       "1                                  0.0                            0.0   \n",
       "2                                  0.0                            0.0   \n",
       "3                                  0.0                            0.0   \n",
       "4                                  0.0                            0.0   \n",
       "...                                ...                            ...   \n",
       "995                                0.0                            0.0   \n",
       "996                                0.0                            0.0   \n",
       "997                                0.0                            0.0   \n",
       "998                                0.0                            0.0   \n",
       "999                                0.0                            0.0   \n",
       "\n",
       "           slovnet_syntax_relation_iobj  \n",
       "sample_id                                \n",
       "0                                   0.0  \n",
       "1                                   0.0  \n",
       "2                                   0.0  \n",
       "3                                   0.0  \n",
       "4                                   0.0  \n",
       "...                                 ...  \n",
       "995                                 0.0  \n",
       "996                                 0.0  \n",
       "997                                 0.0  \n",
       "998                                 0.0  \n",
       "999                                 0.0  \n",
       "\n",
       "[1000 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted = core.extract(idb)\n",
    "extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f5e69-8534-446a-aef2-ab8215001720",
   "metadata": {},
   "source": [
    "* Для каждого слова получили все признаки из pymorphy, slovnet..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08039c7d-48b0-4d7a-b5b1-128e1c93ede7",
   "metadata": {},
   "source": [
    "* Нам необходим контекст слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15527c-77cd-4b6c-8bd8-78e2c825c932",
   "metadata": {},
   "source": [
    "Будем использовать `PlainContextBuilder`.  Он построит двойной индекс.\n",
    "\n",
    "* хотим исключить само слово из контекста, поэтому `include_zero_offset=False`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd869e7c",
   "metadata": {},
   "source": [
    "#### Пример PlainContextBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb1077c-4498-448a-af52-32a64dfd1de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>1903357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <th>2</th>\n",
       "      <td>2011235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">998</th>\n",
       "      <th>1</th>\n",
       "      <td>2021284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">999</th>\n",
       "      <th>1</th>\n",
       "      <td>2021284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4027 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  another_word_id\n",
       "sample_id offset                 \n",
       "0         0                     7\n",
       "1         0                     7\n",
       "2         0                514887\n",
       "3         0                514887\n",
       "4         0               1903357\n",
       "...                           ...\n",
       "997       2               2011235\n",
       "998       1               2021284\n",
       "          2               2021285\n",
       "999       1               2021284\n",
       "          2               2021285\n",
       "\n",
       "[4027 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronoun_pcb = PlainContextBuilder(include_zero_offset=True,\n",
    "                                  left_to_right_contexts_proportion=0.5)\n",
    "pronoun_pcb.sentence_id_column_name = 'pronoun_sentence_id'\n",
    "pronoun_pcb.word_id_column_name = 'pronoun_word_id'\n",
    "pronoun_contexts = pronoun_pcb.build_context(idb, context_size=5)\n",
    "pronoun_contexts  # TODO у некоторых только offsset == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3e5494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>offset</th>\n",
       "      <th>another_word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>514886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>514885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>514888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>514889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id  offset  another_word_id\n",
       "2             2       0           514887\n",
       "1004          2      -1           514886\n",
       "1005          2      -2           514885\n",
       "2031          2       1           514888\n",
       "2032          2       2           514889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = pronoun_contexts.reset_index()\n",
    "cdf.loc[cdf.sample_id == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394440ba",
   "metadata": {},
   "source": [
    "#### WordContextAssemblyPoint (~ ContextualBinding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c68dbb",
   "metadata": {},
   "source": [
    "Задача AssemblyPoint'a (он же ContextualBinding) - порождать экстракторами батчи в том виде, в котором они будут приняты сетью. Для LSTM будет 3d-тензор. Для Plain-сети будет плоский датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395fd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plain_context(pcb):\n",
    "    return ContextualBinding(\n",
    "    name='plain_context',\n",
    "    context_length=3,\n",
    "    network_type=ContextualNetworkType.Plain,\n",
    "    hidden_size=[30],\n",
    "    context_builder=pcb,\n",
    "    extractor=CoreExtractor(join_column='another_word_id'),\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "pronoun_plain_context = get_plain_context(pronoun_pcb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92aa50",
   "metadata": {},
   "source": [
    "**Пояснение:**\n",
    "По умолчанию CoreExtractor пытается мерджить по word_id. В нашем случае CoreExtractor отработает после создания PlainContextBuilder'ом двойного индекса. \n",
    "Для добавления признаков слов из контекста будем join'ить по столбцу another_word_id. Поэтому join_column='another_word_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae35c19",
   "metadata": {},
   "source": [
    "Для создания согласованных экстракторов и сетей у AssemblyPoint есть методы create_extractor и create_network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc9aac",
   "metadata": {},
   "source": [
    "У такой сети на последнем слое hidden_size нейронов. Ее выход можно подать в другую сеть, которая будет выдавать вероятности классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afeb414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:15:08.101732+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-06 08:15:08.382607+00:00 INFO: Success\n",
      "2022-12-06 08:15:08.383604+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-06 08:15:08.613070+00:00 INFO: Success\n",
      "2022-12-06 08:15:08.613070+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-06 08:15:08.896158+00:00 INFO: Success\n",
      "2022-12-06 08:15:08.898155+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-06 08:15:08.900156+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n",
      "2022-12-06 08:15:08.903158+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-06 08:15:08.908160+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n"
     ]
    }
   ],
   "source": [
    "pronoun_context_extractor = pronoun_plain_context.create_extractor(task=None, bundle=idb)\n",
    "pronoun_context_extractor.fit(idb)\n",
    "# not_batch = core_extractor.extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa95cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = pronoun_plain_context.create_network_factory(\n",
    "    task=None, input=None)  # None это ок. это legacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8a14c",
   "metadata": {},
   "source": [
    "#### Batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5c17e",
   "metadata": {},
   "source": [
    "Иногда нам нужны фичи контекстов нескольких слов. Например, в задаче поиска антецедентов это местоимение и два существительных - потенциальные антецеденты. Для каждого из этих слов создадим экстрактор (для каждого экстрактора будет отдельная голова нейросети). Batcher примет список этих экстракторов и создаст батч.\n",
    "\n",
    "`+` нам понадобится экстрагировать лейблы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f8f8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label\n",
       "sample_id       \n",
       "0              1\n",
       "1              0\n",
       "2              1\n",
       "3              0\n",
       "4              0\n",
       "5              0\n",
       "6              1\n",
       "7              0\n",
       "8              0\n",
       "9              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import Conventions\n",
    "from tg.common.ml import dft\n",
    "# экстрагирует лейблы. Получается one-hot df. Лейблы пойдут в loss function.\n",
    "\n",
    "\n",
    "def get_binary_label_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=None))\n",
    "    return label_extractor\n",
    "\n",
    "\n",
    "def test_extractor(extractor, bundle):\n",
    "    extractor.fit(bundle)\n",
    "    return extractor.extract(bundle)\n",
    "\n",
    "test_extractor(get_binary_label_extractor(), idb).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3b06cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:15:10.699193+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-06 08:15:10.931424+00:00 INFO: Success\n",
      "2022-12-06 08:15:10.931424+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-06 08:15:11.146169+00:00 INFO: Success\n",
      "2022-12-06 08:15:11.146169+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-06 08:15:11.354129+00:00 INFO: Success\n",
      "2022-12-06 08:15:11.369755+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-06 08:15:11.369755+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n",
      "2022-12-06 08:15:11.369755+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-06 08:15:11.369755+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n"
     ]
    }
   ],
   "source": [
    "batcher = Batcher(batch_size=1000, extractors=[\n",
    "                  pronoun_context_extractor, get_binary_label_extractor()])\n",
    "batch = batcher.fit_extract(idb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9addb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = factory.create_network(task=None, input=batch)\n",
    "network(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d0281",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++\n",
    "+++++++++++++++++++++++\n",
    "+++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e69b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml.batched_training.torch.networks.extracting_network import FeedForwardNetwork\n",
    "from tg.common.ml.batched_training.torch.networks.simple_networks import FullyConnectedNetwork, ParallelNetwork\n",
    "\n",
    "def get_head_factory(sentence_id_column_name, word_id_column_name):\n",
    "    pcb = PlainContextBuilder(include_zero_offset=True, left_to_right_contexts_proportion=0.5)\n",
    "    pcb.sentence_id_column_name = sentence_id_column_name\n",
    "    pcb.word_id_column_name = word_id_column_name\n",
    "    plain_context = ContextualBinding(\n",
    "        name='plain_context',\n",
    "        context_length=3,\n",
    "        network_type=ContextualNetworkType.Plain,\n",
    "        hidden_size=[30],\n",
    "        context_builder=pcb,\n",
    "        extractor=CoreExtractor(join_column='another_word_id'),\n",
    "        debug=False\n",
    "    )\n",
    "    return plain_context.create_network_factory(task=None, input=None)\n",
    "\n",
    "\n",
    "class HeadsUnionNetwork(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 sizes: List[int],\n",
    "                 heads,\n",
    "                 outs,\n",
    "                 output: Union[None, torch.Tensor, int] = None):\n",
    "        super(HeadsUnionNetwork, self).__init__()\n",
    "        heads_forward_networks = dict()\n",
    "        for i in range(len(heads)):\n",
    "            fully_connected = FullyConnectedNetwork(sizes=[3], input=outs[i].shape[1], output=output)\n",
    "            heads_forward_networks[str(i)] = FeedForwardNetwork(heads[i], fully_connected, torch.nn.Softmax(dim=1))\n",
    "        self.parallel_network = ParallelNetwork()\n",
    "        self.parallel_network.networks = torch.nn.ModuleDict(heads_forward_networks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        heads_outputs = self.parallel_network(input)\n",
    "        concat = torch.cat([torch.transpose(x, 0, 1) for x in heads_outputs.values()], dim=0)\n",
    "        parallel_mean = torch.mean(concat, 0)\n",
    "        return parallel_mean.view(len(parallel_mean), 1)\n",
    "    \n",
    "\n",
    "class MultiheadNetworkFactory:\n",
    "    def __init__(self, *head_factories):\n",
    "        self.head_factories = [*head_factories]\n",
    "\n",
    "    def create_network(self, task, input):\n",
    "        heads = [f.create_network(task=None, input=input) for f in self.head_factories]\n",
    "        outs = [h(input) for h in heads]\n",
    "\n",
    "        return HeadsUnionNetwork(sizes=[3], heads=heads, outs=outs, output=input['label'].shape[1])\n",
    "\n",
    "pronoun_head_factory = get_head_factory('pronoun_sentence_id', 'pronoun_word_id')\n",
    "candidate_head_factory = get_head_factory('candidate_sentence_id', 'candidate_word_id')\n",
    "network_factory = MultiheadNetworkFactory(pronoun_head_factory, candidate_head_factory)\n",
    "assembled_network = network_factory.create_network(task=None, input=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea0b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add_sklearn(roc_auc_score)\n",
    "        self.instantiate_default_task(epoch_count=10, batch_size=1000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(data, [pronoun_context_extractor, get_binary_label_extractor()])\n",
    "        self.setup_model(network_factory)\n",
    "        \n",
    "task = ClassificationTask()\n",
    "#result = task.run(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b07714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer, mini_batch_indices):\n",
    "    for mini_batch_num, mini_batch_index in enumerate(mini_batch_indices):\n",
    "        mini_batch = batcher.get_mini_batch(index = mini_batch_indices[mini_batch_num], batch = batch)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(mini_batch)\n",
    "        loss = loss_fn(pred, torch.tensor(mini_batch['label'].values, dtype=torch.float32))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2c7eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "optimizer = torch.optim.SGD(assembled_network.parameters(), lr=learning_rate)\n",
    "\n",
    "mini_batch_indices = batcher.get_mini_batch_indices(mini_batch_size = 10, batch = batch)\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(assembled_network, torch.nn.CrossEntropyLoss(), optimizer, mini_batch_indices)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e7d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc242c8a",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0056c0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch_indices = batcher.get_mini_batch_indices(mini_batch_size = 10, batch = batch)\n",
    "mini_batch = batcher.get_mini_batch(index = mini_batch_indices[0], batch = batch)\n",
    "mini_batch['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c781561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.6754, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, input)\n",
    "output.backward()\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, optimizer):\n",
    "    for mini_batch_num, mini_batch_index in enumerate(mini_batch_indices):\n",
    "        mini_batch = batcher.get_mini_batch(index = mini_batch_indices[mini_batch_num], batch = batch)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(mini_batch)\n",
    "        loss = loss_fn(pred, torch.tensor(mini_batch['label'].values, dtype=torch.float32))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cf4481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "optimizer = torch.optim.SGD(assembled_network.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(assembled_network, torch.nn.CrossEntropyLoss(), optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15015434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label\n",
       "sample_id       \n",
       "0              1\n",
       "1              0\n",
       "2              1\n",
       "3              0\n",
       "4              0\n",
       "5              0\n",
       "6              1\n",
       "7              0\n",
       "8              0\n",
       "9              0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f89d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = assembled_network(batch)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df0b225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ClassificationNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, sample):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(sample['features'].shape[1], hidden_size)\n",
    "        self.output = torch.nn.Linear(hidden_size, sample['label'].shape[1])\n",
    "\n",
    "    def forward(self, input):\n",
    "        X = input['features']\n",
    "        X = torch.tensor(X.astype(float).values).float()\n",
    "        X = self.hidden(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        X = self.output(X)\n",
    "        X = torch.sigmoid(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d5db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.ml.components.training_task_factory import TaskFactory, Conventions\n",
    "from tg.common.ml import dft\n",
    "\n",
    "\n",
    "class MulticlassMetrics(bt.Metric):\n",
    "    def __init__(self, add_accuracy=True, add_rating=False):\n",
    "        self.add_accuracy = add_accuracy\n",
    "        self.add_rating = add_rating\n",
    "\n",
    "    def get_names(self):\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append('accuracy')\n",
    "        if self.add_rating:\n",
    "            result.append('rating')\n",
    "        return result\n",
    "\n",
    "    def measure(self, df, _):\n",
    "        prefix = 'true_label_'\n",
    "        labels = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix):\n",
    "                labels.append(c.replace(prefix, ''))\n",
    "\n",
    "        def ustack(df, prefix, cols, name):\n",
    "            df = df[[prefix+c for c in cols]]\n",
    "            df.columns = [c for c in cols]\n",
    "            df = df.unstack().to_frame(name)\n",
    "            return df\n",
    "\n",
    "        predicted = ustack(df, 'predicted_label_', labels, 'predicted')\n",
    "        true = ustack(df, 'true_label_', labels, 'true')\n",
    "        df = predicted.merge(true, left_index=True,\n",
    "                             right_index=True).reset_index()\n",
    "        df.columns = ['label', 'sample', 'predicted', 'true']\n",
    "        df = df.feed(fluq.add_ordering_column(\n",
    "            'sample', ('predicted', False), 'predicted_rating'))\n",
    "\n",
    "        match = (df.loc[df.predicted_rating ==\n",
    "                 0].set_index('sample').true > 0.5)\n",
    "        rating = df.loc[df.true > 0.5].set_index('sample').predicted_rating\n",
    "        result = []\n",
    "        if self.add_accuracy:\n",
    "            result.append(match.mean())\n",
    "        if self.add_rating:\n",
    "            result.append(rating.mean())\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13188570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilabel_extractor():\n",
    "    label_extractor = (bt.PlainExtractor\n",
    "                       .build(Conventions.LabelFrame)\n",
    "                       .index()\n",
    "                       .apply(take_columns=['label'], transformer=dft.DataFrameTransformerFactory.default_factory())\n",
    "                       )\n",
    "    return label_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a313ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:15:27.635127+00:00 INFO: Training starts. Info: {}\n",
      "2022-12-06 08:15:27.642128+00:00 INFO: Ensuring/loading bundle. Bundle before:\n",
      "<tg.common.ml.batched_training.data_bundle.IndexedDataBundle object at 0x000001AB912AEEE0>\n",
      "2022-12-06 08:15:27.652130+00:00 INFO: Bundle loaded\n",
      "{'index': {'shape': (101065, 7), 'index_name': 'sample_id', 'columns': ['pronoun_word_id', 'pronoun_sentence_id', 'candidate_word_id', 'candidate_sentence_id', 'candidate_distance', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'pymorphy': {'shape': (570787, 16), 'index_name': 'word_id', 'columns': ['normal_form', 'alternatives', 'score', 'delta_score', 'POS', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'slovnet': {'shape': (570787, 17), 'index_name': 'word_id', 'columns': ['POS', 'Case', 'Animacy', 'Gender', 'Number', '...'], 'index': [0, 1, 2, 3, 4, '...']}, 'src': {'shape': (570787, 14), 'index_name': None, 'columns': ['word_id', 'sentence_id', 'word_index', 'paragraph_id', 'word_tail', '...'], 'index': [0, 1, 2, 3, 4, '...']}}\n",
      "2022-12-06 08:15:27.658133+00:00 INFO: Index frame is set to index, shape is (1000, 8)\n",
      "2022-12-06 08:15:27.666134+00:00 INFO: Skipping late initialization\n",
      "2022-12-06 08:15:27.677140+00:00 INFO: Preprocessing bundle by batcher\n",
      "2022-12-06 08:15:27.691145+00:00 INFO: Splits: train 700, test 300, display 300\n",
      "2022-12-06 08:15:27.693141+00:00 INFO: New training. Instantiating the system\n",
      "2022-12-06 08:15:27.697142+00:00 INFO: Fitting the transformers\n",
      "2022-12-06 08:15:27.702144+00:00 INFO: Fitting extractor pymorphy in CoreExtractor\n",
      "2022-12-06 08:15:28.087104+00:00 INFO: Success\n",
      "2022-12-06 08:15:28.090105+00:00 INFO: Fitting extractor slovnet_morph in CoreExtractor\n",
      "2022-12-06 08:15:28.590759+00:00 INFO: Success\n",
      "2022-12-06 08:15:28.591759+00:00 INFO: Fitting extractor slovnet_syntax in CoreExtractor\n",
      "2022-12-06 08:15:28.928840+00:00 INFO: Success\n",
      "2022-12-06 08:15:28.929841+00:00 INFO: Fitting extractor syntax_fixes in CoreExtractor\n",
      "2022-12-06 08:15:28.932842+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n",
      "2022-12-06 08:15:28.937843+00:00 INFO: Fitting extractor syntax_stats in CoreExtractor\n",
      "2022-12-06 08:15:28.940846+00:00 INFO: Skipped as the corresponding frame is missing from the bundle\n",
      "2022-12-06 08:15:29.835657+00:00 INFO: Instantiating model\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m task \u001b[38;5;241m=\u001b[39m ClassificationTask()\n\u001b[0;32m     14\u001b[0m idb \u001b[38;5;241m=\u001b[39m IndexedDataBundle(db\u001b[38;5;241m.\u001b[39mindex, db)\n\u001b[1;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43midb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\training_core\\arch.py:78\u001b[0m, in \u001b[0;36mAbstractTrainingTask.run\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any):\n\u001b[0;32m     77\u001b[0m     env \u001b[38;5;241m=\u001b[39m InMemoryTrainingEnvironment()\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\grammar_ru\\ml\\components\\training_task_factory\\torch_task_factory.py:47\u001b[0m, in \u001b[0;36mTaskFactory.run_with_environment\u001b[1;34m(self, data, env)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_task(data, env)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:354\u001b[0m, in \u001b[0;36mBatchedTrainingTask.run_with_environment\u001b[1;34m(self, _bundle, env)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, _bundle: Union[\u001b[38;5;28mstr\u001b[39m, Path, DataBundle], env: Optional[TrainingEnvironment] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 354\u001b[0m     temp_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization completed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    357\u001b[0m     temp_data\u001b[38;5;241m.\u001b[39mtrain_bundle \u001b[38;5;241m=\u001b[39m temp_data\u001b[38;5;241m.\u001b[39moriginal_ibundle\u001b[38;5;241m.\u001b[39mchange_index(temp_data\u001b[38;5;241m.\u001b[39msplit\u001b[38;5;241m.\u001b[39mtrain)\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:177\u001b[0m, in \u001b[0;36mBatchedTrainingTask._prepare_all\u001b[1;34m(self, bundle, env)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    176\u001b[0m     Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew training. Instantiating the system\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instantiate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mibundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchange_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     first_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\common\\ml\\batched_training\\training_task.py:125\u001b[0m, in \u001b[0;36mBatchedTrainingTask._instantiate_all\u001b[1;34m(self, ibundle)\u001b[0m\n\u001b[0;32m    122\u001b[0m test_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatcher\u001b[38;5;241m.\u001b[39mfit_extract(ibundle)\n\u001b[0;32m    124\u001b[0m Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstantiating model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\alexandra\\desktop\\grammar_ru\\tg\\grammar_ru\\ml\\components\\training_task_factory\\torch_model_handler.py:48\u001b[0m, in \u001b[0;36mTorchModelHandler.instantiate\u001b[1;34m(self, task, input)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_factory\u001b[38;5;241m.\u001b[39mcreate_network(task, \u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_ctor\u001b[38;5;241m.\u001b[39minstantiate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_ctor()\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mClassificationTask.create_task.<locals>.<lambda>\u001b[1;34m(_, sample)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate_default_task(\n\u001b[0;32m      5\u001b[0m     epoch_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, mini_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metric_pool\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_batcher(\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# data, [get_feature_extractor(), get_multilabel_extractor()])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     data, [core, get_multilabel_extractor()])\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model(\u001b[38;5;28;01mlambda\u001b[39;00m _, sample: \u001b[43mClassificationNetwork\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mClassificationNetwork.__init__\u001b[1;34m(self, hidden_size, sample)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, sample):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ClassificationNetwork, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_size)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(hidden_size, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "class ClassificationTask(TaskFactory):\n",
    "    def create_task(self, data, env):\n",
    "        metrics = bt.MetricPool().add(MulticlassMetrics())  # TODO epoch_count=20\n",
    "        self.instantiate_default_task(\n",
    "            epoch_count=1, batch_size=10000, mini_batch_size=None, metric_pool=metrics)\n",
    "        self.setup_batcher(\n",
    "            # data, [get_feature_extractor(), get_multilabel_extractor()])\n",
    "            data, [core, get_multilabel_extractor()])\n",
    "        self.setup_model(lambda _, sample: ClassificationNetwork(\n",
    "            20, sample), learning_rate=1)\n",
    "\n",
    "\n",
    "task = ClassificationTask()\n",
    "idb = IndexedDataBundle(db.index, db)\n",
    "result = task.run(idb)\n",
    "# pd.DataFrame(result['output']['history']).set_index('iteration').plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f9e0f",
   "metadata": {},
   "source": [
    "setup_butcher принимает экстракторы. Передадим core? или завернем его в get_feature_extractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce965d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
