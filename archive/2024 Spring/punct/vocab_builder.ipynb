{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tg.common import DataBundle\n",
    "from tg.grammar_ru.common import Loc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBundle.load(Loc.bundles_path/'punct/9kk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tg.common import DataBundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabBuilder:\n",
    "    def __init__(self, lang='russian'):\n",
    "        self._morph_analyzer = pymorphy2.MorphAnalyzer()\n",
    "        # self._stop_words = stopwords.words(lang)\n",
    "        self._cached_words = {}\n",
    "\n",
    "    def build_vocab(self, db: DataBundle, vocab_size=10_000, filter_stop_words=False) -> pd.DataFrame:\n",
    "        normalized = pd.Series(self.get_normalized_words(db.src.word))\n",
    "        if filter_stop_words:\n",
    "            stop_words = stopwords.words(lang)\n",
    "            filtered = normalized[~normalized.isin(stop_words)]\n",
    "            frequency = filtered.value_counts()\n",
    "        else:\n",
    "            frequency = normalized.value_counts()\n",
    "        \n",
    "        taken_words = frequency[:vocab_size]\n",
    "\n",
    "        return self._convert_to_vocab_frame(taken_words)\n",
    "\n",
    "    def _convert_to_vocab_frame(self, taken_words: pd.Series) -> pd.DataFrame:\n",
    "        vocab_df = taken_words.to_frame()\n",
    "        vocab_df.columns = ['count']\n",
    "        vocab_df['vocab_id'] = np.arange(len(taken_words))\n",
    "        vocab_df.rename(columns={'0': 'count'}, inplace=True)\n",
    "        vocab_df.index.name = 'word'\n",
    "\n",
    "        vocab_df.loc['UNK'] = [0, -1]\n",
    "        vocab_df.vocab_id += 1\n",
    "        vocab_df.sort_values('vocab_id', inplace=True)\n",
    "\n",
    "        return vocab_df\n",
    "\n",
    "    def get_normal_form(self, word: str) -> str:\n",
    "        return self._morph_analyzer.parse(word)[0].normal_form\n",
    "\n",
    "    def get_normalized_words(self, words: tp.Iterable[str]) -> tp.Sequence[str]:\n",
    "        normalized_words = []\n",
    "        for word in words:\n",
    "            if word in self._cached_words:\n",
    "                normalized_form = self._cached_words[word]\n",
    "            else:\n",
    "                normalized_form = self.get_normal_form(word)\n",
    "                self._cached_words[word] = normalized_form\n",
    "            normalized_words.append(normalized_form)\n",
    "\n",
    "        return normalized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_builder = VocabBuilder()\n",
    "vocab_df = vocab_builder.build_vocab(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>vocab_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UNK</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>870752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>366886</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>в</th>\n",
       "      <td>272738</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>и</th>\n",
       "      <td>205288</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>бабочка</th>\n",
       "      <td>57</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>солженицын</th>\n",
       "      <td>57</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>очнуться</th>\n",
       "      <td>57</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>беляев</th>\n",
       "      <td>57</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>соломенный</th>\n",
       "      <td>57</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             count  vocab_id\n",
       "word                        \n",
       "UNK              0         0\n",
       ",           870752         1\n",
       ".           366886         2\n",
       "в           272738         3\n",
       "и           205288         4\n",
       "...            ...       ...\n",
       "бабочка         57      9996\n",
       "солженицын      57      9997\n",
       "очнуться        57      9998\n",
       "беляев          57      9999\n",
       "соломенный      57     10000\n",
       "\n",
       "[10001 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df.to_parquet(Loc.bundles_path/'punct/9kk/word_to_vocab.parquet')\n",
    "vocab_df.to_parquet('word_to_vocab.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.features import SimpleFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabFeaturizer(SimpleFeaturizer):\n",
    "    def __init__(self, path_to_vocab):\n",
    "        super().__init__('vocab')\n",
    "        self.path_to_vocab = path_to_vocab\n",
    "        self.morpy_analyzer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def _featurize_inner(self, db):\n",
    "        vocab_df = pd.read_parquet(self.path_to_vocab)\n",
    "\n",
    "        db.src['normalized_word'] = self._get_normalized_words(db.src.word)\n",
    "        merged = db.src.merge(vocab_df, how='left', left_on='normalized_word', right_on='word')\n",
    "        result = merged[['word_id', 'word', 'vocab_id']].copy()\n",
    "        result.vocab_id = result.vocab_id.fillna(0)\n",
    "        result.vocab_id = result.vocab_id.astype(int)\n",
    "\n",
    "        return result.set_index('word_id', drop=True)\n",
    "\n",
    "    def _get_normal_form(self, word):\n",
    "        return self.morpy_analyzer.parse(word)[0].normal_form\n",
    "\n",
    "    def _get_normalized_words(self, words):\n",
    "        cached_words = {}\n",
    "        normalized_words = []\n",
    "        for word in db.src.word:\n",
    "            if word in cached_words:\n",
    "                normalized_form = cached_words[word]\n",
    "            else:\n",
    "                normalized_form = self._get_normal_form(word)\n",
    "                cached_words[word] = normalized_form\n",
    "            normalized_words.append(normalized_form)\n",
    "\n",
    "        return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavecFeaturizer(SimpleFeaturizer):\n",
    "    def __init__(self, navec):\n",
    "        self.navec = navec\n",
    "        self.morpy_analyzer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    def _featurize_inner(self, db):\n",
    "        db.src['normalized_word'] = self._get_normalized_words(db.src.word)\n",
    "        word_ids = [navec.vocab.get(word, navec.vocab.unk_id) for word in db.src.normalized_word]\n",
    "        result = db.src[['word_id', 'word']].copy()\n",
    "        result['navec_id'] = word_ids\n",
    "        result.navec_id = result.navec_id.astype(int)\n",
    "\n",
    "        return result.set_index('word_id', drop=True)\n",
    "\n",
    "    def _get_normal_form(self, word):\n",
    "        return self.morpy_analyzer.parse(word)[0].normal_form\n",
    "\n",
    "    def _get_normalized_words(self, words):\n",
    "        cached_words = {}\n",
    "        normalized_words = []\n",
    "        for word in db.src.word:\n",
    "            if word in cached_words:\n",
    "                normalized_form = cached_words[word]\n",
    "            else:\n",
    "                normalized_form = self._get_normal_form(word)\n",
    "                cached_words[word] = normalized_form\n",
    "            normalized_words.append(normalized_form)\n",
    "\n",
    "        return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_featurizer = VocabFeaturizer('word_to_vocab.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized = vocab_featurizer._featurize_inner(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized.to_parquet(Loc.bundles_path/'punct/9kk/sample_to_vocab.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "\n",
    "navec = Navec.load('navec_hudlit_v1_12B_500K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>navec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>По</td>\n",
       "      <td>302187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>словам</td>\n",
       "      <td>403005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Шварца</td>\n",
       "      <td>484700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>все</td>\n",
       "      <td>74009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514098</th>\n",
       "      <td>разговоре</td>\n",
       "      <td>361422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514099</th>\n",
       "      <td>с</td>\n",
       "      <td>383451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514100</th>\n",
       "      <td>The</td>\n",
       "      <td>12631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514101</th>\n",
       "      <td>Guardian</td>\n",
       "      <td>5383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9514102</th>\n",
       "      <td>.</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9023195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  navec_id\n",
       "word_id                     \n",
       "0               По    302187\n",
       "1           словам    403005\n",
       "2           Шварца    484700\n",
       "3                ,    500000\n",
       "4              все     74009\n",
       "...            ...       ...\n",
       "9514098  разговоре    361422\n",
       "9514099          с    383451\n",
       "9514100        The     12631\n",
       "9514101   Guardian      5383\n",
       "9514102          .    500000\n",
       "\n",
       "[9023195 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec_featurizer = NavecFeaturizer(navec)\n",
    "featurized = navec_featurizer._featurize_inner(db)\n",
    "featurized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized.to_parquet(Loc.bundles_path/'punct/9kk/sample_to_navec.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 13 2023, 10:26:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06d5edd100e8af3ad61bcb86118b225055d5ada911b896704585f9e786ce8d1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
