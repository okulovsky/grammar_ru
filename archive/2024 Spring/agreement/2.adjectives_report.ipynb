{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tg.grammar_ru.common import Loc\n",
    "from tg.grammar_ru.corpus import CorpusReader, CorpusBuilder, BucketCorpusBalancer\n",
    "from tg.grammar_ru.corpus.corpus_reader import read_data\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tg.grammar_ru.components.yandex_storage.s3_yandex_helpers import S3YandexHandler\n",
    "from tg.grammar_ru.components.yandex_delivery.training_logs import S3TrainingLogsLoader, TrainingLogsViewer\n",
    "\n",
    "from yo_fluq_ds import Queryable, Query, fluq\n",
    "import plotly.express as px\n",
    "from tg.grammar_ru.common import Separator\n",
    "\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "load_dotenv(Loc.root_path / 'environment.env')\n",
    "\n",
    "\n",
    "def get_tasks(bucket, tasks_list_s3_path):\n",
    "    tmp_local_file = Loc.temp_path / tasks_list_s3_path.split('/')[-1]\n",
    "    S3YandexHandler.download_file(bucket, tasks_list_s3_path, tmp_local_file)\n",
    "    with open(tmp_local_file, 'r') as f:\n",
    "        tasks = ast.literal_eval(f.read())\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def plot_metrics(metrics, title=\"\"):\n",
    "    plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "        metrics, 'accuracy_display'), label='accuracy_display')\n",
    "    plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "        metrics, 'accuracy_test'), label='accuracy_test')\n",
    "    plt.title('')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cm(cm):\n",
    "    fig = go.Figure(data=go.Heatmap(z=cm,\n",
    "                                    text=cm,\n",
    "                                    x=cm.columns,\n",
    "                                    y=cm.index,\n",
    "                                    texttemplate=\"%{text}\",\n",
    "                                    colorscale='Blues'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'agreementproject'\n",
    "dataset_name = 'agreement_adj_mid+_mystemless_0_declination'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(s):\n",
    "    return int(s.split('_label_')[1])\n",
    "\n",
    "def get_true_and_pred(result_df):\n",
    "    pred_col_names = [c for c in result_df.columns if 'predicted_label' in c ]\n",
    "    true_col_names = [c for c in result_df.columns if 'true_label' in c ]\n",
    "    y_pred = result_df[pred_col_names].idxmax(axis=\"columns\").apply(get_label)\n",
    "    true_probs = result_df[true_col_names]\n",
    "    y_true = true_probs.idxmax(axis=\"columns\").apply(get_label)\n",
    "\n",
    "    result_df['pred_label'] = y_pred\n",
    "    result_df['true_label'] = y_true\n",
    "    result_df['pred_score'] = result_df[pred_col_names].max(axis=1)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_words_sents(result_df, src, true_label: int, pred_label: int, worst_words_cnt: int):\n",
    "    one_inst_another = result_df[(result_df.true_label == true_label) & (\n",
    "        result_df.pred_label == pred_label)]\n",
    "    thrsh = one_inst_another[f'predicted_label_{pred_label}'].sort_values(\n",
    "        ascending=False).head(worst_words_cnt).min()\n",
    "    worst_mistakes_scores = one_inst_another[\n",
    "        one_inst_another[f'predicted_label_{pred_label}'] >= thrsh]\n",
    "\n",
    "    worst_words = (src[src.word_id.isin(worst_mistakes_scores.word_id)]\n",
    "                   [['word_id', 'sentence_id', 'word']])[:worst_words_cnt]\n",
    "    worst_sents = worst_words['sentence_id'].unique()\n",
    "    worst_sents_df = src[src.sentence_id.isin(worst_sents)]\n",
    "    # worst_sents_df.loc[worst_sents_df.index, 'pred_score'] = -1\n",
    "    # worst_sents_df.loc[worst_sents_df[worst_sents_df.word_id.isin(worst_mistakes_scores.word_id)].index, \"pred_score\"] = one_inst_another.pred_score.values\n",
    "    return worst_words, worst_sents_df\n",
    "\n",
    "def get_best_words_sents(result_df, src, pred_label: int, words_cnt: int):\n",
    "    \"\"\" \n",
    "    Находит слова, в которых сеть была уверена в ответе и ответ верный\n",
    "    \"\"\"\n",
    "    correct_df = result_df[result_df.true_label==pred_label]\n",
    "    thrsh = correct_df[f'predicted_label_{pred_label}'].sort_values(\n",
    "        ascending=False).head(words_cnt).min()\n",
    "    best_scores = correct_df[correct_df[f'predicted_label_{pred_label}']>=thrsh]\n",
    "    best_words = (src[src.word_id.isin(best_scores.word_id)])[['word_id', 'sentence_id', 'word']][:words_cnt]\n",
    "    best_sents = best_words.sentence_id.unique()\n",
    "    best_sents_df = src[src.sentence_id.isin(best_sents)]\n",
    "    return best_words, best_sents_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {'ая', 'ого', 'ое', 'ой', 'ом', 'ому',\n",
    "       'ою', 'ую', 'ые', 'ый', 'ым', 'ыми', 'ых'} # тут нет окнчаний превосходных форм\n",
    "\n",
    "# полнейшей, наипрочнейшего, важнейшие,меньшим, милейший, наистраннейшее, новейших, малейшем, слабейшему, меньшими\n",
    "good = {'ая', 'его', 'ее', 'ей', 'ем', 'ему',\n",
    "        'ие', 'ий', 'им', 'ими', 'их', 'ую', 'яя', 'юю'}\n",
    "\n",
    "big = {'ая', 'ие', 'им', 'ими', 'их', 'ого',\n",
    "       'ое', 'ой', 'ом', 'ому', 'ою', 'ую'}\n",
    "\n",
    "POSSIBLE_ENDINGS = set().union(new, good, big)\n",
    "endings_nums = {e: i for i, e in enumerate(\n",
    "    sorted(list(POSSIBLE_ENDINGS)))}\n",
    "num_by_ending = endings_nums\n",
    "ending_by_num = {v:k for k, v in endings_nums.items()}\n",
    "\n",
    "new_declination_labels = {num for e, num in endings_nums.items() if e in new}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете только слова 1-го типа склонения. Новый. Возможно 13 окончаний. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_by_ending = {e:num for e,num in num_by_ending.items() if e in new}\n",
    "new_num_by_ending"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставили только слова типа \"Новый\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.common import DataBundle\n",
    "from tg.common.ml.batched_training import IndexedDataBundle\n",
    "from tg.grammar_ru.components.plain_context_builder import PlainContextBuilder\n",
    "bundle_0_declination_path = Loc.data_cache_path/'bundles/agreement/mid+_mystemless_0_declination'\n",
    "bundle_full_0_declination_path = Loc.data_cache_path/'bundles/agreement/full_mystemless_0_declination'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DataBundle.load(Loc.data_cache_path/'bundles/agreement/full_mystemless')\n",
    "# ids_0_type=set(db.src[db.src.declension_type==0].word_id)\n",
    "# db['index'] = db.index[db.index.word_id.isin(ids_0_type) & db.index.label.isin(new_declination_labels)]\n",
    "# db = db.copy()\n",
    "# db.save(Loc.data_cache_path/'bundles/agreement/full_mystemless_0_declination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBundle.load(Loc.data_cache_path/'bundles/agreement/mid+_mystemless')\n",
    "# ids_0_type=set(db.src[db.src.declension_type==0].word_id)\n",
    "# db['index'] = db.index[db.index.word_id.isin(ids_0_type) & db.index.label.isin(new_declination_labels)]\n",
    "# db = db.copy()\n",
    "# db.save(bundle_0_declination_path)\n",
    "# # idb = IndexedDataBundle(db.index, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.syntax_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.src.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим отфильтрованный бандл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del db\n",
    "db = DataBundle.load(bundle_0_declination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.src[db.src.word_id.isin(db.index.word_id)].declension_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все возможные окончания слов 0-го типа склонения. \"Новый\"\n",
    "db.index.label.replace(ending_by_num).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.index.label.isin(new_declination_labels).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_ids = db.index.groupby('label').word_id.first()\n",
    "# db.src[db.src.word_id.isin(word_ids)].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = db.src[db.src.word_id.isin(word_ids)].label\n",
    "# ls[~ls.isin(new_num_by_ending.values())]#.replace(ending_by_num))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отправка бандла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'agreementproject'\n",
    "dataset_name = 'agreement_adj_mid+_mystemless_0_declination'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.components.yandex_storage.s3_yandex_helpers import S3YandexHandler\n",
    "# try:\n",
    "#     S3YandexHandler.create_bucket(bucket)\n",
    "# except:\n",
    "#     pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = f'datasphere/{project_name}/datasets/{dataset_name}'\n",
    "S3YandexHandler.upload_folder(bucket, s3path, bundle_0_declination_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_parquet(bundle_0_declination_path/'index.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(db.index.label.replace(ending_by_num), histnorm=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(db.index.label.replace(ending_by_num), color=db.index.split)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DataBundle.load(bundle_full_0_declination_path)\n",
    "# fig = px.histogram(db.index.label.replace(ending_by_num), histnorm=None)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {ending_by_num[num]:occ_cnt for num, occ_cnt in dict(db.index.label.value_counts()).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'agreementproject'\n",
    "dataset_name = 'agreement_adj_mid_1st_declination'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.components.yandex_delivery.training_logs import S3TrainingLogsLoader, TrainingLogsViewer\n",
    "tasks = get_tasks()\n",
    "loader = S3TrainingLogsLoader(bucket, project_name)\n",
    "metrics = loader.load_metrics(tasks)\n",
    "plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "    metrics, 'accuracy_display'), label='accuracy_display')\n",
    "plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "    metrics, 'accuracy_test'), label='accuracy_test')\n",
    "plt.title('')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipped_folder = (Loc.root_path /\n",
    "                   'temp'/'training_results' /\n",
    "                   f'{task_name}.unzipped')\n",
    "result_df = pd.read_parquet(unzipped_folder/'output'/'result_df.parquet')\n",
    "y_true, y_pred = get_true_and_pred(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                       normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {ending_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {ending_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=go.Heatmap(z=cm,\n",
    "                                text=cm,\n",
    "                                x=cm.columns,\n",
    "                                y=cm.index,\n",
    "                                texttemplate=\"%{text}\",\n",
    "                                colorscale='Blues'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                    #    normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {ending_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {ending_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=go.Heatmap(z=cm,\n",
    "                                text=cm,\n",
    "                                x=cm.columns,\n",
    "                                y=cm.index,\n",
    "                                texttemplate=\"%{text}\",\n",
    "                                colorscale='Blues'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src[src.label==16][['word','split']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### without mystem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'agreementproject'\n",
    "dataset_name = 'agreement_adj_mid+_mystemless_1st_declination'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.components.yandex_delivery.training_logs import S3TrainingLogsLoader, TrainingLogsViewer\n",
    "tasks = get_tasks(bucket, 'datasphere/agreementproject/job_info/job_agreementproject_08:21:13.312924.txt')\n",
    "\n",
    "loader = S3TrainingLogsLoader(bucket, project_name)\n",
    "metrics = loader.load_metrics(tasks)\n",
    "\n",
    "unzipped_folder = (Loc.root_path /\n",
    "                   'temp'/'training_results' /\n",
    "                   f'{tasks[0]}.unzipped')\n",
    "result_df = pd.read_parquet(unzipped_folder/'output'/'result_df.parquet')\n",
    "y_true, y_pred = get_true_and_pred(result_df)\n",
    "\n",
    "\n",
    "plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "    metrics, 'accuracy_display'), label='accuracy_display')\n",
    "plt.plot(TrainingLogsViewer.get_metric_by_job(\n",
    "    metrics, 'accuracy_test'), label='accuracy_test')\n",
    "plt.title('')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                     #    normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n,ending_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n,ending_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(z=cm,\n",
    "                                text=cm,\n",
    "                                x=cm.columns,\n",
    "                                y=cm.index,\n",
    "                                texttemplate=\"%{text}\",\n",
    "                                colorscale='Blues'))\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые классы вообще не предсказаны.\n",
    "Возможно бага в интерпретации ответов модели с последнего слоя. Посмотрим на предсказанные числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col_names = [c for c in result_df.columns if 'predicted_label' in c ]\n",
    "result_df[pred_col_names].sum(axis=1).hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых строчках все числа близки к нулю. То есть их нельзя воспринимать как вероятности.\n",
    "Добавим в сеть softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax+Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks = get_tasks(bucket, 'datasphere/agreementproject/job_info/job_agreementproject_10:15:11.216535.txt')\n",
    "\n",
    "# loader = S3TrainingLogsLoader(bucket, project_name)\n",
    "# metrics = loader.load_metrics(tasks)\n",
    "\n",
    "# unzipped_folder = (Loc.root_path /\n",
    "#                    'temp'/'training_results' /\n",
    "#                    f'{tasks[0]}.unzipped')\n",
    "# result_df = pd.read_parquet(unzipped_folder/'output'/'result_df.parquet')\n",
    "# y_true, y_pred = get_true_and_pred(result_df)\n",
    "\n",
    "# plot_metrics(metrics)\n",
    "# sorted_nums = sorted(list(y_true.unique()))\n",
    "# cm = pd.DataFrame(\n",
    "#     confusion_matrix(y_true, y_pred,\n",
    "#                      #    normalize='true'\n",
    "#                      ).round(2),\n",
    "#     columns=[f'pred {n,ending_by_num[n]}' for n in sorted_nums],\n",
    "#     index=[f'actual {n,ending_by_num[n]}' for n in sorted_nums]\n",
    "# )\n",
    "\n",
    "# fig = go.Figure(data=go.Heatmap(z=cm,\n",
    "#                                 text=cm,\n",
    "#                                 x=cm.columns,\n",
    "#                                 y=cm.index,\n",
    "#                                 texttemplate=\"%{text}\",\n",
    "#                                 colorscale='Blues'))\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = get_tasks(bucket, 'datasphere/agreementproject/job_info/job_agreementproject_09:53:58.071673.txt')\n",
    "\n",
    "loader = S3TrainingLogsLoader(bucket, project_name)\n",
    "metrics = loader.load_metrics(tasks)\n",
    "\n",
    "unzipped_folder = (Loc.root_path /\n",
    "                   'temp'/'training_results' /\n",
    "                   f'{tasks[0]}.unzipped')\n",
    "result_df = pd.read_parquet(unzipped_folder/'output'/'result_df.parquet')\n",
    "y_true, y_pred = get_true_and_pred(result_df)\n",
    "\n",
    "plot_metrics(metrics)\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                     #    normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {n,ending_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {n,ending_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col_names = [c for c in result_df.columns if 'predicted_label' in c ]\n",
    "true_col_names = [c for c in result_df.columns if 'true_label' in c ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(result_df[pred_col_names].values.reshape(-1), histnorm=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col_names = [c for c in result_df.columns if 'predicted_label' in c ]\n",
    "# result_df[pred_col_names+[\"pred_label\", \"true_label\",\"label\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые классы не предсказаны.\n",
    "Посмотрим на эти случаи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBundle.load(Loc.data_cache_path/'bundles/agreement/mid+_mystemless_1st_declination')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = db.src\n",
    "src.declension_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_by_ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.common import Separator\n",
    "\n",
    "pred_label = 19\n",
    "true_label = 15\n",
    "worst_words, worst_sents_df = get_worst_words_sents(\n",
    "    result_df, db.src, true_label=true_label, pred_label=pred_label, worst_words_cnt=50)\n",
    "# result_df, db.src, true_label=14, pred_label=13, worst_words_cnt=50)\n",
    "print(f\"Predicted  {ending_by_num[pred_label]}  instead of  {ending_by_num[true_label]} \" )\n",
    "Separator.Viewer().tooltip(\"word_id\").color('word_id',\n",
    "                                            value_to_color={\n",
    "                                                wid: 'red' for wid in worst_words.word_id}\n",
    "                                            ).to_html_display(worst_sents_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df[(result_df.true_label==21) & (result_df.pred_label==20)]\n",
    "result_df[(result_df.true_label==14) & (result_df.pred_label==13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_words, best_sents_df = get_best_words_sents(\n",
    "    result_df, db.src, pred_label=0, words_cnt=5)\n",
    "\n",
    "Separator.Viewer().tooltip(\"word_id\").color('word_id',\n",
    "                                            value_to_color={\n",
    "                                                wid: 'green' for wid in best_words.word_id}\n",
    "                                            ).to_html_display(best_sents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.pred_label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# classification_report(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neatly filter bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'agreementproject'\n",
    "dataset_name = 'agreement_adj_mid+_mystemless_0_declination'\n",
    "bucket = 'agreementadjbucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = get_tasks(bucket, 'datasphere/agreementproject/job_info/job_agreementproject_07:13:16.756552.txt')\n",
    "\n",
    "loader = S3TrainingLogsLoader(bucket, project_name)\n",
    "metrics = loader.load_metrics(tasks)\n",
    "\n",
    "unzipped_folder = (Loc.root_path /\n",
    "                   'temp'/'training_results' /\n",
    "                   f'{tasks[0]}.unzipped')\n",
    "result_df = pd.read_parquet(unzipped_folder/'output'/'result_df.parquet')\n",
    "y_true, y_pred = get_true_and_pred(result_df)\n",
    "\n",
    "plot_metrics(metrics)\n",
    "sorted_nums = sorted(list(y_true.unique()))\n",
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred,\n",
    "                     #    normalize='true'\n",
    "                     ).round(2),\n",
    "    columns=[f'pred {ending_by_num[n]}' for n in sorted_nums],\n",
    "    index=[f'actual {ending_by_num[n]}' for n in sorted_nums]\n",
    ")\n",
    "plot_cm(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные проблемы связаны с низкочастотными классами: ом, ому, ою, ым.\n",
    "\n",
    "ОЮ встречается всего 4 раза в датасете.\n",
    "\n",
    "ОМ, ОМУ предсказаны как ЫЙ - самый частотный класс.\n",
    "\n",
    "ЫМ предсказано как ЫЙ, ЫМИ.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worst_sents_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.pred_score.round(2).value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 14% случаев ответ - random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col_names = [c for c in result_df.columns if 'predicted_label' in c ]\n",
    "true_col_names = [c for c in result_df.columns if 'true_label' in c ]\n",
    "result_df[pred_col_names].round(2)[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых строчках распределение вероятности почти равномерное по всем классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(result_df.pred_score, histnorm=None)\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.common import Separator\n",
    "\n",
    "true_label = 15\n",
    "pred_label = 19\n",
    "worst_words, worst_sents_df = get_worst_words_sents(\n",
    "    result_df, db.src, true_label=true_label, pred_label=pred_label, worst_words_cnt=40)\n",
    "print(f\"Predicted  {ending_by_num[pred_label]}  instead of  {ending_by_num[true_label]} \" )\n",
    "Separator.Viewer().tooltip(\"word_id\").color('word_id',\n",
    "                                            value_to_color={\n",
    "                                                wid: 'red' for wid in worst_words.word_id}\n",
    "                                            ).to_html_display(worst_sents_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_words, best_sents_df = get_best_words_sents(\n",
    "    result_df, db.src, pred_label=0, words_cnt=5)\n",
    "\n",
    "Separator.Viewer().tooltip(\"word_id\").color('word_id',\n",
    "                                            value_to_color={\n",
    "                                                wid: 'green' for wid in best_words.word_id}\n",
    "                                            ).to_html_display(best_sents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(result_df.label.replace(ending_by_num), histnorm=None)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "Возможно, вероятности распределяются равномерно потому что loss - mse.\n",
    "Заменим на кросс-энтропию.\n",
    "\n",
    "ОЮ нужно выкинуть из бандла.\n",
    "\n",
    "В бандле был slovnet, его тоже нужно выкинуть потому что он некорректно работает на предложениях с ошибками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
