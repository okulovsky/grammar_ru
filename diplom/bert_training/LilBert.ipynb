{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:58.856252Z",
     "start_time": "2024-05-23T08:38:53.643724Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from grammar_ru.corpus import CorpusReader, CorpusBuilder\n",
    "from diplom.utils.corpus_utils import CorpusFramework\n",
    "from diplom.utils.dialog_markuper import DialogMarkupFeaturizer\n",
    "#from diplom.utils.speech_action_maker import SpeechActionFeaturizer\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:58.869028Z",
     "start_time": "2024-05-23T08:38:58.858067Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.get_device_properties(0)",
   "id": "258d8dc0569ebe2d",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.023076Z",
     "start_time": "2024-05-23T08:38:58.871785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0')\n",
    "path_corpus = Path(f\"../data/corpora/diplom.wow.zip\")\n",
    "corpus = CorpusReader(path_corpus)\n",
    "corpus_framework = CorpusFramework(corpus)\n",
    "authors = corpus.get_toc().author.unique()"
   ],
   "id": "66603ac4cac437d4",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.117297Z",
     "start_time": "2024-05-23T08:38:59.025951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_corpus = pd.read_csv('../text_corpus.csv')\n",
    "\n",
    "labels = text_corpus['action'].unique().tolist()\n",
    "labels = [s.strip() for s in labels ]\n",
    "\n",
    "id2label={id:label for id,label in enumerate(labels)}\n",
    "\n",
    "label2id={label:id for id,label in enumerate(labels)}\n",
    "#there is deleting said words\n",
    "text_corpus = text_corpus.loc[text_corpus.action != 'said']\n",
    "\n",
    "text_corpus[\"labels\"]=text_corpus.action.map(lambda x: label2id[x.strip()])\n",
    "text_corpus = text_corpus.drop(['sample_id','action'], axis=1).rename({'speech':'text'},axis=1)\n",
    "NUM_LABELS= text_corpus.labels.nunique()\n",
    "\n",
    "labels\n"
   ],
   "id": "183debdb047cef65",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.472053Z",
     "start_time": "2024-05-23T08:38:59.119467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "y = text_corpus['labels'].values\n",
    "class_weights= torch.from_numpy(compute_class_weight('balanced',classes=np.unique(y),y=y)).float().to(device)"
   ],
   "id": "9c114281d292dc94",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.478816Z",
     "start_time": "2024-05-23T08:38:59.473557Z"
    }
   },
   "cell_type": "code",
   "source": "class_weights.shape",
   "id": "90d32535bf436808",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.884157Z",
     "start_time": "2024-05-23T08:38:59.480823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4 # 4 is totaly work fine\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-06#1e-05\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-cased')"
   ],
   "id": "c3909f0cce5dd2cf",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.893407Z",
     "start_time": "2024-05-23T08:38:59.886275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.text[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.labels[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "id": "d7bee5fb56d2b82d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.907392Z",
     "start_time": "2024-05-23T08:38:59.895739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = 0.8\n",
    "train_dataset=text_corpus.sample(frac=train_size,random_state=200)\n",
    "test_dataset=text_corpus.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(text_corpus.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = MyDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = MyDataset(test_dataset, tokenizer, MAX_LEN)"
   ],
   "id": "c6d91c2884f842fe",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.918546Z",
     "start_time": "2024-05-23T08:38:59.911980Z"
    }
   },
   "cell_type": "code",
   "source": "training_set.data.labels.nunique()",
   "id": "e0e50ca77462dae8",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.926485Z",
     "start_time": "2024-05-23T08:38:59.920797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0\n",
    "               }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ],
   "id": "d3e75f40b4046dc3",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:38:59.946003Z",
     "start_time": "2024-05-23T08:38:59.928832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")#AutoModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)#torch.nn.Linear(512, 768)#\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, NUM_LABELS)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ],
   "id": "9fe843bafb1d485f",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:01.793826Z",
     "start_time": "2024-05-23T08:38:59.947765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ],
   "id": "b1f94f1d77c39c74",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:02.907187Z",
     "start_time": "2024-05-23T08:39:01.795744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "#scheduler = get_linear_schedule_with_warmup(optimizer, 3, 10)"
   ],
   "id": "bf60ae8bfbce0792",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:02.917846Z",
     "start_time": "2024-05-23T08:39:02.910192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "def apk(actual, predicted, k=5):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if len(actual) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n"
   ],
   "id": "39f3a1e504145c45",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:02.930327Z",
     "start_time": "2024-05-23T08:39:02.920323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, epoch,per_step=1000):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    apk_sum = 0\n",
    "    model.train()\n",
    "    k = 0\n",
    "    for _, data in enumerate(tqdm(training_loader), 0):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "        apk_sum += apk(big_idx, targets, k=5)\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if _ % per_step == 0 and _ != 0:\n",
    "            loss_step = tr_loss / nb_tr_steps\n",
    "            accu_step = (n_correct * 100) / nb_tr_examples\n",
    "            print(f\"Loss over {per_step * k} steps: {loss_step}\")\n",
    "            print(f\"Accuracy over {per_step* k} steps: {accu_step}\")\n",
    "            print(f\"MAP@5over {per_step* k} steps: {apk_sum /nb_tr_examples}\")#(per_step* k)\n",
    "            k += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    print(f\"MAP@5over Epoch: {apk_sum /nb_tr_examples}\")\n",
    "    return"
   ],
   "id": "da5c20af18ad7f10",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:02.943320Z",
     "start_time": "2024-05-23T08:39:02.932472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def valid(model, testing_loader,per_step=100):\n",
    "    tr_loss = 0\n",
    "    apk_sum = 0\n",
    "    k = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    # mb comment\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tqdm(testing_loader), 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            apk_sum += apk(big_idx, targets, k=5)\n",
    "            if _%per_step==0 and _ != 0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per {per_step* k} steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per {per_step* k} steps: {accu_step}\")\n",
    "                print(f\"MAP@5over {per_step* k} steps: {apk_sum /nb_tr_examples}\")\n",
    "                k += 1\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    epoch_map = apk_sum /nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    print(f\"MAP@5over Epoch: {apk_sum /nb_tr_examples}\")\n",
    "    return epoch_accu,epoch_map"
   ],
   "id": "7439efea81d6cb13",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:39:02.950145Z",
     "start_time": "2024-05-23T08:39:02.945866Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 5",
   "id": "a79d4557097b9a86",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T08:49:26.835900Z",
     "start_time": "2024-05-23T08:39:02.952631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(model,epoch,per_step=1300)\n",
    "    valid(model,testing_loader,per_step=700)\n",
    "    #scheduler.step()"
   ],
   "id": "35c40eab77d94f06",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "95bfae3948d2d0ec",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:28:44.690620Z",
     "start_time": "2024-05-21T17:28:30.662040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc,map = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ],
   "id": "568d2dab3f9ef49e",
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:29:40.820884Z",
     "start_time": "2024-05-21T17:29:40.811225Z"
    }
   },
   "cell_type": "code",
   "source": "out[4]",
   "id": "ae29f4d461de917a",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:27:23.535581Z",
     "start_time": "2024-05-21T17:27:23.529138Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_LABELS",
   "id": "f8479894fa08350e",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:26:20.530113Z",
     "start_time": "2024-05-21T17:26:20.509325Z"
    }
   },
   "cell_type": "code",
   "source": "[id2label[ans-1] for ans in answers]",
   "id": "b8de9bcc9d548a24",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:17:19.478149Z",
     "start_time": "2024-05-21T17:17:18.969389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_model_file = './models/first_distilbert.bin'\n",
    "output_vocab_file = './models/first_vocab_distilbert.bin'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)"
   ],
   "id": "afe7f5b5b682dd9c",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:19:21.223767Z",
     "start_time": "2024-05-21T17:19:20.278372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, DistilBertForSequenceClassification\n",
    "loaded_model = DistilBertForSequenceClassification.from_pretrained(output_model_file)\n",
    "predict_label = pipeline('sentiment-analysis', model=loaded_model, tokenizer=tokenizer)"
   ],
   "id": "ffc2eff9789fc5d3",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d840966756e5f780",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
