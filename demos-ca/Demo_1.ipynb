{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative Articulator \n",
    "\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we will look at all the processes in Creative Articulator namely:\n",
    " - the creation of a parallel corpus\n",
    " - the division of text into fragments \n",
    " - translation of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel corpus\n",
    "\n",
    "A parallel corpus is a handy tool that allows you to link parts from different corpus. With it, all the corpus will be stored in a single zip file.\n",
    "\n",
    "In this demonstration, we will work with texts and retellings of Fyodor Mikhailovich Dostoevsky's novel Crime and Punishment, which are located in the `source` folder.\n",
    "\n",
    "\n",
    "The first step is to create a corpus of texts and retellings that are stored in md format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сorpus for English text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.corpus import CorpusBuilder\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Path('./files/eng_crime_and_puhishment.base.zip'),\n",
    "    Path('./source/book/eng'),\n",
    "    ['book']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.corpus import CorpusReader\n",
    "\n",
    "\n",
    "eng_book_reader = CorpusReader(Path('./files/eng_crime_and_puhishment.base.zip'))\n",
    "eng_book = eng_book_reader.get_toc().index\n",
    "\n",
    "eng_book_reader.get_toc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus for English retelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Path('./files/eng_retell.base.zip'),\n",
    "    Path('./source/retell/eng'),\n",
    "    ['book']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_retell_reader = CorpusReader(Path('./files/eng_retell.base.zip'))\n",
    "eng_retell = eng_retell_reader.get_toc().index\n",
    "eng_retell_reader.get_toc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сorpus for Russian text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Path('./files/ru_crime_and_puhishment.base.zip'),\n",
    "    Path('./source/book/ru'),\n",
    "    ['book']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_book_reader = CorpusReader(Path('./files/ru_crime_and_puhishment.base.zip'))\n",
    "ru_book = ru_book_reader.get_toc().index\n",
    "ru_book_reader.get_toc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus for Russian retelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Path('./files/ru_retell.base.zip'),\n",
    "    Path('./source/retell/ru'),\n",
    "    ['book']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_retell_reader = CorpusReader(Path('./files/ru_retell.base.zip'))\n",
    "ru_retell = ru_retell_reader.get_toc().index\n",
    "ru_retell_reader.get_toc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we form a parallel corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_relation(df_1,df_2,name_1,name_2):\n",
    "    rel_1 = {'file_1':df_1, 'file_2':df_2,'relation_name':f\"{name_1}_{name_2}\"}\n",
    "    rel_2 = {'file_1':df_2, 'file_2':df_1,'relation_name':f\"{name_2}_{name_1}\"}\n",
    "    rel = pd.concat([rel_1,rel_2])\n",
    "    return rel\n",
    "\n",
    "def add_dfs(name):\n",
    "    frames = list(name.get_frames())\n",
    "    dfs = dict(zip(name.get_toc().index,frames))\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(ru_book_reader),\n",
    "    \"ru_book\",\n",
    "    None)\n",
    "\n",
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(ru_retell_reader),\n",
    "    \"ru_retell\",\n",
    "    None)\n",
    "\n",
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(eng_retell_reader),\n",
    "    \"eng_retell\",\n",
    "    None)\n",
    "\n",
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/parallel_corpus.zip'),\n",
    "    add_dfs(eng_book_reader),\n",
    "    \"eng_book\",\n",
    "    None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that all parts have been successfully recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ru_book', 'ru_retell', 'eng_retell', 'eng_book'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = CorpusReader(Path('./files/parallel_corpus.zip'))\n",
    "\n",
    "df = reader.get_toc()\n",
    "\n",
    "df.subcorpus_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.grammar_ru.corpus import ParallelCorpus\n",
    "parallel_corpus = ParallelCorpus(Path('./files/parallel_corpus.zip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.projects.retell.translate.utils import get_array_chapters\n",
    "\n",
    "ru_retell_text = get_array_chapters(parallel_corpus.ru_retell)\n",
    "eng_retell_text = get_array_chapters(parallel_corpus.eng_retell)\n",
    "ru_book_text = get_array_chapters(parallel_corpus.ru_book)\n",
    "\n",
    "\n",
    "print(ru_book_text[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.projects.retell.translate.utils import translate\n",
    "translate_retell = translate(eng_retell_text)\n",
    "print(translate_retell[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.projects.retell.retell_utils.metrics import get_jaccard_index\n",
    "from tg.projects.retell.translate.utils import jac_metric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "jaccard_sim = np.array([get_jaccard_index(ru_book_text[i],ru_retell_text[i]) for i in range(len(ru_retell_text))])\n",
    "jac_metric(jaccard_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_sim = np.array([get_jaccard_index(ru_book_text[i],translate_retell[i]) for i in range(len(ru_retell_text))])\n",
    "jac_metric(jaccard_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yo_fluq_ds import FileIO\n",
    "\n",
    "result = ''\n",
    "\n",
    "for text in translate_retell:\n",
    "    result += \"\\n## part\\n\"\n",
    "\n",
    "    result += text\n",
    "\n",
    "\n",
    "FileIO.write_text(result, Path(\"./source/translate/translate.md\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.convert_interformat_folder_to_corpus(\n",
    "    Path('./files/translate.base.zip'),\n",
    "    Path('./source/translate'),\n",
    "    ['book']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_translate_reader = CorpusReader(Path('./files/translate.base.zip'))\n",
    "ru_translate_reader.get_toc() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorpusBuilder.update_parallel_data(\n",
    "    Path('./files/translate.base.zip'),\n",
    "    add_dfs(ru_translate_reader),\n",
    "    \"ru_translate\",\n",
    "    None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
